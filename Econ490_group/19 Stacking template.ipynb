{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking\n",
    "\n",
    "#### Table of Contents\n",
    "\n",
    "- [Preliminaries](#Preliminaries)\n",
    "- [Base Learners](#Base-Learners)\n",
    "    - [Ridge](#Ridge)\n",
    "    - [KNN](#KNN)\n",
    "    - [RF](#RF)\n",
    "    - [Best Base Learner](#Best-Base-Learner)\n",
    "- [Average](#Average)\n",
    "- [Weighted Average](#Weighted-Average)\n",
    "- [Model 1: OLS Average](#Model-1:-OLS-Average)\n",
    "- [Model 2: RF Aggregation](#Model-2:-RF-Aggregation)\n",
    "\n",
    "*************\n",
    "# Preliminaries\n",
    "[TOP](#Stacking)\n",
    "\n",
    "We will be using the following base learners predicting `pct_d_rgdp` in an ensemble using the aggregation techniques listed in the table of contents:\n",
    "\n",
    "1. Ridge Regression\n",
    "2. KNN\n",
    "3. RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilties\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "\n",
    "# algorithms\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/hubst/Econ490_group/class_data.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to exclude the fixed effect features for `year` to reduce the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = ['year', 'urate_bin', 'GeoName']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to make the choice of standardizing all of our variables.\n",
    "\n",
    "Remember, we need to obtain the data for\n",
    "\n",
    "- `train1`\n",
    "- `train2`\n",
    "- `test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['pct_d_rgdp']\n",
    "x = df.drop(columns = 'pct_d_rgdp')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                   train_size = 2/3,\n",
    "                                                   random_state = 490)\n",
    "\n",
    "x_train1, x_train2, y_train1, y_train2 = train_test_split(x_train, y_train,\n",
    "                                                         train_size = 1/2,\n",
    "                                                         random_state = 490)\n",
    "x_train1 = x_train1.apply(stdz)\n",
    "x_train2 = x_train2.apply(stdz)\n",
    "x_test = x_test.apply(stdz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing what we do not need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV\t KFold\t KNeighborsRegressor\t LinearRegression\t RandomForestRegressor\t RidgeCV\t acc\t df\t np\t \n",
      "pd\t r2\t rmse\t stdz\t tqdm\t train_test_split\t x\t x_test\t x_train\t \n",
      "x_train1\t x_train2\t y\t y_test\t y_train\t y_train1\t y_train2\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV\t KFold\t KNeighborsRegressor\t LinearRegression\t RandomForestRegressor\t RidgeCV\t acc\t np\t pd\t \n",
      "r2\t rmse\t stdz\t tqdm\t train_test_split\t x\t x_test\t x_train1\t x_train2\t \n",
      "y\t y_test\t y_train1\t y_train2\t \n"
     ]
    }
   ],
   "source": [
    "%who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********\n",
    "# Base Learners\n",
    "[TOP](#Stacking)\n",
    "\n",
    "In this demonstration, we are only going to use 3 base learners.\n",
    "However, there is nothing stopping your from using more.\n",
    "In fact, you may find that the more learners you have, the better your model.\n",
    "\n",
    "However, once you start to include a larger number of base learners, you may want to consider using regularization to aggregate their predictions.\n",
    "\n",
    "*************\n",
    "## Ridge\n",
    "[TOP](#Stacking)\n",
    "\n",
    "We will be using a ridge regression function from `sklearn`, which means we do not need to append an intercept to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "615.8482110660254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_ridge = RidgeCV(alphas = 10.**np.linspace(-2, 5, num = 20),\n",
    "                   cv = 5).fit(x_train1, y_train1)\n",
    "reg_ridge.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030267374601945285"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_ridge = reg_ridge.score(x_test, y_test)\n",
    "r2_ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***************\n",
    "# KNN\n",
    "[TOP](#Stacking)\n",
    "\n",
    "Remember that KNN is relatively slow at fitting and relatively slow at predicting.\n",
    "All the other models we have used so far are at least relatively fast at predicting.\n",
    "\n",
    "**Why is KNN slow at predicting?** *Hint: it is in its name!*\n",
    "\n",
    "Let the CV begin! We are going to set a hard limit of 100 on the number of neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.75 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  30 out of  30 | elapsed:    6.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 100}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'n_neighbors': [5, 10, 25, 50, 75, 100]\n",
    "}\n",
    "\n",
    "knn_cv = KNeighborsRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(knn_cv, param_grid,\n",
    "                          cv = 5,\n",
    "                          scoring = 'neg_mean_squared_error',\n",
    "                          verbose = 2,\n",
    "                          n_jobs = 4).fit(x_train1, y_train1)\n",
    "\n",
    "best_knn = grid_search.best_params_\n",
    "best_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to refit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02748795325609321"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_knn = KNeighborsRegressor(n_neighbors = best_knn['n_neighbors'])\n",
    "reg_knn.fit(x_train1, y_train1)\n",
    "\n",
    "r2_knn = reg_knn.score(x_test, y_test)\n",
    "r2_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************\n",
    "## RF\n",
    "[TOP](#Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.11536385809625882"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "reg_rf = RandomForestRegressor(n_estimators = 500,\n",
    "                              max_features = 'sqrt',\n",
    "                              random_state = 490,\n",
    "                              n_jobs = 4).fit(x_train1, y_train1)\n",
    "\n",
    "r2_rf = reg_rf.score(x_test, y_test)\n",
    "r2_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************\n",
    "## Best Base Learner\n",
    "[TOP](#Stacking)\n",
    "\n",
    "We can print out the base learners $R^2$ performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'r2_ridge': 0.030267374601945285, 'r2_knn': 0.02748795325609321, 'r2_rf': -0.11536385809625882} \n",
      "\n",
      "r2_ridge : 0.030267374601945285\n"
     ]
    }
   ],
   "source": [
    "r2_base = {\n",
    "    'r2_ridge': r2_ridge,\n",
    "    'r2_knn': r2_knn,\n",
    "    'r2_rf': r2_rf\n",
    "}\n",
    "print(r2_base, '\\n')\n",
    "\n",
    "best_base = max(r2_base, key = r2_base.get)\n",
    "\n",
    "print(best_base, ':', r2_base[best_base])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********\n",
    "# Average\n",
    "[TOP](#Stacking)\n",
    "\n",
    "Remember that the coefficients (the wieghts) are predetermined for a simple average. \n",
    "They are specifically set to the inverse of the number of base learners. \n",
    "To see this, let $j$ denote the base learner index.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\bar{f_j}(x) & = \\frac{1}{3}\\sum_{j=1}^3 f_j(x)\\\\\n",
    "    & = \\frac{1}{3}f_1(x) + \\frac{1}{3}f_2(x) + \\frac{1}{3}f_3(x)\\\\\n",
    "    & = w_1 f_1(x) + w_2 f_2(x) + w_3 f_3(x)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "MATH!!!!!\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ridge</th>\n",
       "      <th>knn</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17195</th>\n",
       "      <th>2003</th>\n",
       "      <td>1.518422</td>\n",
       "      <td>0.961779</td>\n",
       "      <td>2.104121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ridge       knn        rf\n",
       "fips  year                              \n",
       "17195 2003  1.518422  0.961779  2.104121"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_yhat = pd.DataFrame({\n",
    "    'ridge': reg_ridge.predict(x_test),\n",
    "    'knn': reg_knn.predict(x_test),\n",
    "    'rf': reg_rf.predict(x_test)\n",
    "},\n",
    "index = y_test.index)\n",
    "df_test_yhat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.025247656239703153"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_avg = r2(df_test_yhat.mean(axis = 1), y_test)\n",
    "r2_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************\n",
    "# Weighted Average\n",
    "[TOP](#Stacking)\n",
    "\n",
    "In order to estimate a weighted average, we need to create a grid of weights such that they all add to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1331, 3) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(62, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size = 0.1\n",
    "wts = np.arange(0, 1 + step_size, step = step_size)\n",
    "\n",
    "wts_grid = np.array([(x, y, z) for x in wts for y in wts for z in wts])\n",
    "\n",
    "print(wts_grid.shape, '\\n')\n",
    "\n",
    "keep = wts_grid.sum(axis = 1) == 1\n",
    "wts_grid = wts_grid[keep]\n",
    "wts_grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to be using the predicted values on `train2` to identify the optimal weights.\n",
    "\n",
    "It is computationally efficient to only estimate them once, so we are going to create a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ridge</th>\n",
       "      <th>knn</th>\n",
       "      <th>rf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fips</th>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48333</th>\n",
       "      <th>2014</th>\n",
       "      <td>2.683669</td>\n",
       "      <td>1.241488</td>\n",
       "      <td>9.149495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ridge       knn        rf\n",
       "fips  year                              \n",
       "48333 2014  2.683669  1.241488  9.149495"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train2_yhat = pd.DataFrame({\n",
    "    'ridge': reg_ridge.predict(x_train2),\n",
    "    'knn': reg_knn.predict(x_train2),\n",
    "    'rf': reg_rf.predict(x_train2)\n",
    "},\n",
    "index = y_train2.index)\n",
    "df_train2_yhat.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to identify the optimal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 62/62 [00:00<00:00, 476.81it/s]\n"
     ]
    }
   ],
   "source": [
    "r2_grid = {}\n",
    "\n",
    "i = 0\n",
    "for w in tqdm(wts_grid):\n",
    "    yhat = df_train2_yhat @ w.T\n",
    "    r2_grid[i] = r2(yhat, y_train2)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4, 0.5, 0.1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_indx = max(r2_grid, key = r2_grid.get)\n",
    "best_wts = wts_grid[best_indx]\n",
    "best_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the $R^2$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03451625498360489"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = df_test_yhat @ best_wts.T\n",
    "\n",
    "r2_wtd_avg = r2(yhat, y_test)\n",
    "r2_wtd_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************\n",
    "# Model 1: OLS Average\n",
    "[TOP](#Stacking)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How is OLS an average?**\n",
    "\n",
    "Well with a slight abuse of notation, recall that in this case OLS takes the form\n",
    "\n",
    "$$\\hat{y} = \\beta_0 + \\hat{y}_1 \\beta_1 + \\hat{y}_2 \\beta_2 + \\hat{y}_3 \\beta_3 $$\n",
    "\n",
    "Here, $\\beta_1$, $\\beta_2$, and $\\beta_3$ are acting as weights that do not sum to 1.\n",
    "$\\beta_0$ is a *bias* term. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2047342283163347 [0.36456238 0.58770383 0.11487815]\n"
     ]
    }
   ],
   "source": [
    "stack_ols = LinearRegression().fit(df_train2_yhat, y_train2)\n",
    "print(stack_ols.intercept_, stack_ols.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8624101323576985"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_ols.intercept_ + sum(stack_ols.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034619873469761586"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_stack_ols = stack_ols.score(df_test_yhat, y_test)\n",
    "r2_stack_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************\n",
    "# Model 2: RF Aggregation\n",
    "[TOP](#Stacking)\n",
    "\n",
    "We can also use different models as stackers.\n",
    "\n",
    "Here we will use a random forest. \n",
    "We will use the usual `max_features = 'sqrt'`, however, we will also add "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.031020593654738526"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack_rf = RandomForestRegressor(n_estimators = 50,\n",
    "                                max_features = 'sqrt',\n",
    "                                max_depth = 2,\n",
    "                                random_state = 490,\n",
    "                                n_jobs = 3)\n",
    "stack_rf.fit(df_train2_yhat, y_train2)\n",
    "\n",
    "r2_stack_rf = stack_rf.score(df_test_yhat, y_test)\n",
    "r2_stack_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "# Comparison\n",
    "[TOP](#Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                Type                     Data/Info\n",
      "----------------------------------------------------------\n",
      "GridSearchCV            ABCMeta                  <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
      "KFold                   ABCMeta                  <class 'sklearn.model_selection._split.KFold'>\n",
      "KNeighborsRegressor     ABCMeta                  <class 'sklearn.neighbors<...>ion.KNeighborsRegressor'>\n",
      "LinearRegression        ABCMeta                  <class 'sklearn.linear_mo<...>._base.LinearRegression'>\n",
      "RandomForestRegressor   ABCMeta                  <class 'sklearn.ensemble.<...>t.RandomForestRegressor'>\n",
      "RidgeCV                 ABCMeta                  <class 'sklearn.linear_model._ridge.RidgeCV'>\n",
      "acc                     function                 <function acc at 0x0000022530A82310>\n",
      "best_base               str                      r2_ridge\n",
      "best_indx               int                      41\n",
      "best_knn                dict                     n=1\n",
      "best_wts                ndarray                  3: 3 elems, type `float64`, 24 bytes\n",
      "df_test_yhat            DataFrame                               ridge     <...>n[16709 rows x 3 columns]\n",
      "df_train2_yhat          DataFrame                               ridge     <...>n[16709 rows x 3 columns]\n",
      "grid_search             GridSearchCV             GridSearchCV(cv=5, estima<...>quared_error', verbose=2)\n",
      "i                       int                      62\n",
      "keep                    ndarray                  1331: 1331 elems, type `bool`, 1331 bytes\n",
      "knn_cv                  KNeighborsRegressor      KNeighborsRegressor()\n",
      "np                      module                   <module 'numpy' from 'E:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "param_grid              dict                     n=1\n",
      "pd                      module                   <module 'pandas' from 'E:<...>es\\\\pandas\\\\__init__.py'>\n",
      "r2                      function                 <function r2 at 0x0000022530A82430>\n",
      "r2_avg                  float64                  0.025247656239703153\n",
      "r2_base                 dict                     n=3\n",
      "r2_grid                 dict                     n=62\n",
      "r2_knn                  float64                  0.02748795325609321\n",
      "r2_rf                   float64                  -0.11536385809625882\n",
      "r2_ridge                float64                  0.030267374601945285\n",
      "r2_stack_ols            float64                  0.034619873469761586\n",
      "r2_stack_rf             float64                  0.031020593654738526\n",
      "r2_wtd_avg              float64                  0.03451625498360489\n",
      "reg_knn                 KNeighborsRegressor      KNeighborsRegressor(n_neighbors=100)\n",
      "reg_rf                  RandomForestRegressor    RandomForestRegressor(max<...>        random_state=490)\n",
      "reg_ridge               RidgeCV                  RidgeCV(alphas=array([1.0<...>000e+05]),\\n        cv=5)\n",
      "rmse                    function                 <function rmse at 0x0000022530A823A0>\n",
      "stack_ols               LinearRegression         LinearRegression()\n",
      "stack_rf                RandomForestRegressor    RandomForestRegressor(max<...>jobs=3, random_state=490)\n",
      "stdz                    function                 <function stdz at 0x0000022530A824C0>\n",
      "step_size               float                    0.1\n",
      "tqdm                    type                     <class 'tqdm.std.tqdm'>\n",
      "train_test_split        function                 <function train_test_split at 0x0000022533EF1280>\n",
      "w                       ndarray                  3: 3 elems, type `float64`, 24 bytes\n",
      "wts                     ndarray                  11: 11 elems, type `float64`, 88 bytes\n",
      "wts_grid                ndarray                  62x3: 186 elems, type `float64`, 1488 bytes\n",
      "wts_trid                ndarray                  1331x3: 3993 elems, type `float64`, 31944 bytes\n",
      "x                       DataFrame                            pos_net_jobs <...>[50127 rows x 11 columns]\n",
      "x_test                  DataFrame                            pos_net_jobs <...>[16709 rows x 11 columns]\n",
      "x_train1                DataFrame                            pos_net_jobs <...>[16709 rows x 11 columns]\n",
      "x_train2                DataFrame                            pos_net_jobs <...>[16709 rows x 11 columns]\n",
      "y                       Series                   fips   year\\n1001   2002 <...>th: 50127, dtype: float64\n",
      "y_test                  Series                   fips   year\\n17195  2003 <...>th: 16709, dtype: float64\n",
      "y_train1                Series                   fips   year\\n12125  2009 <...>th: 16709, dtype: float64\n",
      "y_train2                Series                   fips   year\\n48333  2014 <...>th: 16709, dtype: float64\n",
      "yhat                    Series                   fips   year\\n17195  2003 <...>th: 16709, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
