{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression-Based Classification\n",
    "\n",
    "#### Table of Contents\n",
    "\n",
    "* [Preliminaries](#Preliminaries)\n",
    "* [Binomial Logistic Regression](#Binomial-Logistic-Regression)\n",
    "    - [Logit Inference](#Logit-Inference)\n",
    "        - [Logit Marginal Effects](#Logit-Marginal-Effects)\n",
    "        - [Comparison to LPM](#Comparison-to-LPM)\n",
    "        - [Logit Regularization](#Logit-Regularization)\n",
    "    - [Logit Prediction Diagnostics](#Logit-Prediction-Diagnostics)\n",
    "        - [Logit Null Model](#Logit-Null-Model)\n",
    "        - [Logit Full Model](#Logit-Full-Model)\n",
    "        - [Alternative Thresholds](#Alternative-Thresholds)\n",
    "- [Multinomial Logistic Regression](#Multinomial-Logistic-Regression)\n",
    "    - [MN Logit Inference](#MN-Logit-Inference)\n",
    "        - [MN Logit Marginal Effects](#MN-Logit-Marginal-Effects)\n",
    "        - [MN Logit Regularization](#MN-Logit-Regularization)\n",
    "    - [MN Logit Prediction Diagnostics](#MN-Logit-Prediction-Diagnostics)\n",
    "        - [MN Logit Null Model](#MN-Logit-Null-Model)\n",
    "        - [MN Logit Full Model](#MN-Logit-Full-Model)\n",
    "\n",
    "***\n",
    "# Preliminaries\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm # progress bar\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model as lm\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(rc = {'axes.titlesize': 24,\n",
    "             'axes.labelsize': 20,\n",
    "             'xtick.labelsize': 12,\n",
    "             'ytick.labelsize': 12,\n",
    "             'figure.figsize': (8, 4.5)})\n",
    "sns.set_style(\"white\") # for plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/hubst/Econ490_group/class_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped = df.drop(columns = ['urate_bin', 'year', 'GeoName']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True),\n",
    "    pd.get_dummies(df.year, drop_first = True)    \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['pos_net_jobs'].astype(float)\n",
    "x = df_prepped.drop(columns = 'pos_net_jobs')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "# Binomial Logistic Regression\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "There are three primary ways to fit a logsitic regression:\n",
    "\n",
    "- `statsmodels.api.Logit(y, x).fit()`\n",
    "- `statsmodels.formula.api.logit(data = df, formula = 'y ~ x').fit()`\n",
    "- `sklearn.linear_model.LogisticRegression().fit(x, y)`\n",
    "\n",
    "************\n",
    "## Logit Inference\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "By now, if you are thinking inference, then you should be thinking `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.598795\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "fit_logit = sm.Logit(y_train, x_train).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>              <td>Logit</td>      <td>Pseudo R-squared:</td>    <td>0.127</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>   <td>pos_net_jobs</td>         <td>AIC:</td>        <td>40077.0933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 14:21</td>       <td>BIC:</td>        <td>40312.7651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33418</td>       <td>Log-Likelihood:</td>    <td>-20011.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>27</td>            <td>LL-Null:</td>        <td>-22913.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33390</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>     <th>z</th>     <th>P>|z|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>-2.1336</td>  <td>0.1494</td>  <td>-14.2851</td> <td>0.0000</td> <td>-2.4263</td> <td>-1.8409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>0.0155</td>   <td>0.0015</td>   <td>10.3856</td> <td>0.0000</td> <td>0.0126</td>  <td>0.0184</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>0.0417</td>   <td>0.0030</td>   <td>14.1236</td> <td>0.0000</td> <td>0.0359</td>  <td>0.0475</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>0.2041</td>   <td>0.0056</td>   <td>36.3848</td> <td>0.0000</td> <td>0.1931</td>  <td>0.2151</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>-0.1647</td>  <td>0.0061</td>  <td>-26.8399</td> <td>0.0000</td> <td>-0.1767</td> <td>-0.1527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>0.0000</td>   <td>0.0000</td>   <td>2.0681</td>  <td>0.0386</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>-0.0033</td>  <td>0.0009</td>   <td>-3.5175</td> <td>0.0004</td> <td>-0.0052</td> <td>-0.0015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>0.0059</td>   <td>0.0010</td>   <td>5.9288</td>  <td>0.0000</td> <td>0.0039</td>  <td>0.0078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>0.0019</td>   <td>0.0014</td>   <td>1.3754</td>  <td>0.1690</td> <td>-0.0008</td> <td>0.0047</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>0.0000</td>   <td>0.0000</td>   <td>1.0236</td>  <td>0.3060</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>0.3610</td>   <td>0.0338</td>   <td>10.6966</td> <td>0.0000</td> <td>0.2949</td>  <td>0.4272</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>0.1662</td>   <td>0.0359</td>   <td>4.6308</td>  <td>0.0000</td> <td>0.0959</td>  <td>0.2366</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2003</th>              <td>1.0495</td>   <td>0.0689</td>   <td>15.2345</td> <td>0.0000</td> <td>0.9145</td>  <td>1.1845</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>1.3234</td>   <td>0.0706</td>   <td>18.7548</td> <td>0.0000</td> <td>1.1851</td>  <td>1.4617</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>1.2072</td>   <td>0.0720</td>   <td>16.7553</td> <td>0.0000</td> <td>1.0660</td>  <td>1.3484</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>1.7648</td>   <td>0.0758</td>   <td>23.2861</td> <td>0.0000</td> <td>1.6162</td>  <td>1.9133</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>0.5726</td>   <td>0.0681</td>   <td>8.4049</td>  <td>0.0000</td> <td>0.4391</td>  <td>0.7062</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>0.8626</td>   <td>0.0690</td>   <td>12.5012</td> <td>0.0000</td> <td>0.7273</td>  <td>0.9978</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>-0.5327</td>  <td>0.0827</td>   <td>-6.4412</td> <td>0.0000</td> <td>-0.6948</td> <td>-0.3706</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>0.2174</td>   <td>0.0717</td>   <td>3.0336</td>  <td>0.0024</td> <td>0.0769</td>  <td>0.3578</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2011</th>              <td>1.3064</td>   <td>0.0703</td>   <td>18.5921</td> <td>0.0000</td> <td>1.1686</td>  <td>1.4441</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>1.5542</td>   <td>0.0722</td>   <td>21.5354</td> <td>0.0000</td> <td>1.4127</td>  <td>1.6956</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>1.2692</td>   <td>0.0709</td>   <td>17.9033</td> <td>0.0000</td> <td>1.1303</td>  <td>1.4082</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>1.5313</td>   <td>0.0727</td>   <td>21.0515</td> <td>0.0000</td> <td>1.3887</td>  <td>1.6739</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>1.6098</td>   <td>0.0737</td>   <td>21.8320</td> <td>0.0000</td> <td>1.4653</td>  <td>1.7543</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>1.3157</td>   <td>0.0721</td>   <td>18.2485</td> <td>0.0000</td> <td>1.1744</td>  <td>1.4570</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>1.1677</td>   <td>0.0705</td>   <td>16.5515</td> <td>0.0000</td> <td>1.0294</td>  <td>1.3060</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2018</th>              <td>1.4274</td>   <td>0.0728</td>   <td>19.6171</td> <td>0.0000</td> <td>1.2848</td>  <td>1.5700</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                          Results: Logit\n",
       "==================================================================\n",
       "Model:               Logit            Pseudo R-squared: 0.127     \n",
       "Dependent Variable:  pos_net_jobs     AIC:              40077.0933\n",
       "Date:                2021-03-02 14:21 BIC:              40312.7651\n",
       "No. Observations:    33418            Log-Likelihood:   -20011.   \n",
       "Df Model:            27               LL-Null:          -22913.   \n",
       "Df Residuals:        33390            LLR p-value:      0.0000    \n",
       "Converged:           1.0000           Scale:            1.0000    \n",
       "No. Iterations:      6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "                   Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "const             -2.1336   0.1494 -14.2851 0.0000 -2.4263 -1.8409\n",
       "pct_d_rgdp         0.0155   0.0015  10.3856 0.0000  0.0126  0.0184\n",
       "emp_estabs         0.0417   0.0030  14.1236 0.0000  0.0359  0.0475\n",
       "estabs_entry_rate  0.2041   0.0056  36.3848 0.0000  0.1931  0.2151\n",
       "estabs_exit_rate  -0.1647   0.0061 -26.8399 0.0000 -0.1767 -0.1527\n",
       "pop                0.0000   0.0000   2.0681 0.0386  0.0000  0.0000\n",
       "pop_pct_black     -0.0033   0.0009  -3.5175 0.0004 -0.0052 -0.0015\n",
       "pop_pct_hisp       0.0059   0.0010   5.9288 0.0000  0.0039  0.0078\n",
       "lfpr               0.0019   0.0014   1.3754 0.1690 -0.0008  0.0047\n",
       "density            0.0000   0.0000   1.0236 0.3060 -0.0000  0.0000\n",
       "lower              0.3610   0.0338  10.6966 0.0000  0.2949  0.4272\n",
       "similar            0.1662   0.0359   4.6308 0.0000  0.0959  0.2366\n",
       "2003               1.0495   0.0689  15.2345 0.0000  0.9145  1.1845\n",
       "2004               1.3234   0.0706  18.7548 0.0000  1.1851  1.4617\n",
       "2005               1.2072   0.0720  16.7553 0.0000  1.0660  1.3484\n",
       "2006               1.7648   0.0758  23.2861 0.0000  1.6162  1.9133\n",
       "2007               0.5726   0.0681   8.4049 0.0000  0.4391  0.7062\n",
       "2008               0.8626   0.0690  12.5012 0.0000  0.7273  0.9978\n",
       "2009              -0.5327   0.0827  -6.4412 0.0000 -0.6948 -0.3706\n",
       "2010               0.2174   0.0717   3.0336 0.0024  0.0769  0.3578\n",
       "2011               1.3064   0.0703  18.5921 0.0000  1.1686  1.4441\n",
       "2012               1.5542   0.0722  21.5354 0.0000  1.4127  1.6956\n",
       "2013               1.2692   0.0709  17.9033 0.0000  1.1303  1.4082\n",
       "2014               1.5313   0.0727  21.0515 0.0000  1.3887  1.6739\n",
       "2015               1.6098   0.0737  21.8320 0.0000  1.4653  1.7543\n",
       "2016               1.3157   0.0721  18.2485 0.0000  1.1744  1.4570\n",
       "2017               1.1677   0.0705  16.5515 0.0000  1.0294  1.3060\n",
       "2018               1.4274   0.0728  19.6171 0.0000  1.2848  1.5700\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logit.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********\n",
    "### Logit Marginal Effects \n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>pos_net_jobs</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>            <td>dydx</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>               <td>overall</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <th></th>             <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>    0.0032</td> <td>    0.000</td> <td>   10.444</td> <td> 0.000</td> <td>    0.003</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>    0.0086</td> <td>    0.001</td> <td>   14.278</td> <td> 0.000</td> <td>    0.007</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>    0.0421</td> <td>    0.001</td> <td>   39.190</td> <td> 0.000</td> <td>    0.040</td> <td>    0.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>   -0.0340</td> <td>    0.001</td> <td>  -27.918</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td> 2.054e-08</td> <td> 9.93e-09</td> <td>    2.069</td> <td> 0.039</td> <td> 1.08e-09</td> <td>    4e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>   -0.0007</td> <td>    0.000</td> <td>   -3.520</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>    0.0012</td> <td>    0.000</td> <td>    5.939</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>    0.0004</td> <td>    0.000</td> <td>    1.376</td> <td> 0.169</td> <td>   -0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td> 1.698e-06</td> <td> 1.66e-06</td> <td>    1.024</td> <td> 0.306</td> <td>-1.55e-06</td> <td> 4.95e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>    0.0745</td> <td>    0.007</td> <td>   10.763</td> <td> 0.000</td> <td>    0.061</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>    0.0343</td> <td>    0.007</td> <td>    4.637</td> <td> 0.000</td> <td>    0.020</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2003</th>              <td>    0.2167</td> <td>    0.014</td> <td>   15.438</td> <td> 0.000</td> <td>    0.189</td> <td>    0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>    0.2732</td> <td>    0.014</td> <td>   19.134</td> <td> 0.000</td> <td>    0.245</td> <td>    0.301</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>    0.2492</td> <td>    0.015</td> <td>   17.026</td> <td> 0.000</td> <td>    0.221</td> <td>    0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>    0.3643</td> <td>    0.015</td> <td>   24.002</td> <td> 0.000</td> <td>    0.335</td> <td>    0.394</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>    0.1182</td> <td>    0.014</td> <td>    8.438</td> <td> 0.000</td> <td>    0.091</td> <td>    0.146</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>    0.1781</td> <td>    0.014</td> <td>   12.609</td> <td> 0.000</td> <td>    0.150</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>   -0.1100</td> <td>    0.017</td> <td>   -6.451</td> <td> 0.000</td> <td>   -0.143</td> <td>   -0.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>    0.0449</td> <td>    0.015</td> <td>    3.035</td> <td> 0.002</td> <td>    0.016</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2011</th>              <td>    0.2697</td> <td>    0.014</td> <td>   18.958</td> <td> 0.000</td> <td>    0.242</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>    0.3208</td> <td>    0.015</td> <td>   22.110</td> <td> 0.000</td> <td>    0.292</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>    0.2620</td> <td>    0.014</td> <td>   18.231</td> <td> 0.000</td> <td>    0.234</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>    0.3161</td> <td>    0.015</td> <td>   21.587</td> <td> 0.000</td> <td>    0.287</td> <td>    0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>    0.3323</td> <td>    0.015</td> <td>   22.429</td> <td> 0.000</td> <td>    0.303</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>    0.2716</td> <td>    0.015</td> <td>   18.597</td> <td> 0.000</td> <td>    0.243</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>    0.2411</td> <td>    0.014</td> <td>   16.809</td> <td> 0.000</td> <td>    0.213</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2018</th>              <td>    0.2947</td> <td>    0.015</td> <td>   20.051</td> <td> 0.000</td> <td>    0.266</td> <td>    0.323</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:           pos_net_jobs\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "=====================================================================================\n",
       "                       dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp            0.0032      0.000     10.444      0.000       0.003       0.004\n",
       "emp_estabs            0.0086      0.001     14.278      0.000       0.007       0.010\n",
       "estabs_entry_rate     0.0421      0.001     39.190      0.000       0.040       0.044\n",
       "estabs_exit_rate     -0.0340      0.001    -27.918      0.000      -0.036      -0.032\n",
       "pop                2.054e-08   9.93e-09      2.069      0.039    1.08e-09       4e-08\n",
       "pop_pct_black        -0.0007      0.000     -3.520      0.000      -0.001      -0.000\n",
       "pop_pct_hisp          0.0012      0.000      5.939      0.000       0.001       0.002\n",
       "lfpr                  0.0004      0.000      1.376      0.169      -0.000       0.001\n",
       "density            1.698e-06   1.66e-06      1.024      0.306   -1.55e-06    4.95e-06\n",
       "lower                 0.0745      0.007     10.763      0.000       0.061       0.088\n",
       "similar               0.0343      0.007      4.637      0.000       0.020       0.049\n",
       "2003                  0.2167      0.014     15.438      0.000       0.189       0.244\n",
       "2004                  0.2732      0.014     19.134      0.000       0.245       0.301\n",
       "2005                  0.2492      0.015     17.026      0.000       0.221       0.278\n",
       "2006                  0.3643      0.015     24.002      0.000       0.335       0.394\n",
       "2007                  0.1182      0.014      8.438      0.000       0.091       0.146\n",
       "2008                  0.1781      0.014     12.609      0.000       0.150       0.206\n",
       "2009                 -0.1100      0.017     -6.451      0.000      -0.143      -0.077\n",
       "2010                  0.0449      0.015      3.035      0.002       0.016       0.074\n",
       "2011                  0.2697      0.014     18.958      0.000       0.242       0.298\n",
       "2012                  0.3208      0.015     22.110      0.000       0.292       0.349\n",
       "2013                  0.2620      0.014     18.231      0.000       0.234       0.290\n",
       "2014                  0.3161      0.015     21.587      0.000       0.287       0.345\n",
       "2015                  0.3323      0.015     22.429      0.000       0.303       0.361\n",
       "2016                  0.2716      0.015     18.597      0.000       0.243       0.300\n",
       "2017                  0.2411      0.014     16.809      0.000       0.213       0.269\n",
       "2018                  0.2947      0.015     20.051      0.000       0.266       0.323\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There is no summary2() method for marginal effects\n",
    "fit_logit.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "### Comparison to LPM \n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "For the sake of not exploding this notebook with summaries, let's use a simplier model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.670589\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>pos_net_jobs</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>            <td>dydx</td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>               <td>overall</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <th></th>            <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>       <td>    0.0057</td> <td>    0.000</td> <td>   16.916</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th> <td>   -0.0286</td> <td>    0.001</td> <td>  -26.454</td> <td> 0.000</td> <td>   -0.031</td> <td>   -0.026</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "        Logit Marginal Effects       \n",
       "=====================================\n",
       "Dep. Variable:           pos_net_jobs\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "====================================================================================\n",
       "                      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           0.0057      0.000     16.916      0.000       0.005       0.006\n",
       "estabs_exit_rate    -0.0286      0.001    -26.454      0.000      -0.031      -0.026\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.Logit(y_train, x_train[['const', 'pct_d_rgdp', 'estabs_exit_rate']]).fit().get_margeff().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const               0.798882\n",
       "pct_d_rgdp          0.004872\n",
       "estabs_exit_rate   -0.027791\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.OLS(y_train, x_train[['const', 'pct_d_rgdp', 'estabs_exit_rate']]).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these values are not identical, they are pretty close to one another. This is because OLS is always a first order approximation. Think/thank Taylor Series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "### Logit Regularization \n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We can also perform regularization, much like OLS:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lm.LogisticRegression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'l1_ratio': 0.2}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.arange(-5, -1, step = 1),\n",
    "    'l1_ratio':  np.arange(0, 1, step = 0.1)\n",
    "}\n",
    "\n",
    "lr_cv = lm.LogisticRegression(penalty = 'elasticnet', solver = 'saga',\n",
    "                              max_iter = 1e3, random_state = 490)\n",
    "grid_search = GridSearchCV(lr_cv, param_grid, \n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = 10)\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best = grid_search.best_params_\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $C = \\frac{1}{\\alpha}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.6141965372354353\n",
      "            Iterations: 45\n",
      "            Function evaluations: 46\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                0.246821\n",
       "pct_d_rgdp           0.120624\n",
       "emp_estabs           0.173485\n",
       "estabs_entry_rate    0.542312\n",
       "estabs_exit_rate    -0.410774\n",
       "pop                  0.031311\n",
       "pop_pct_black       -0.037813\n",
       "pop_pct_hisp         0.072487\n",
       "lfpr                 0.016614\n",
       "density              0.003289\n",
       "lower                0.140961\n",
       "similar              0.033833\n",
       "2003                 0.094805\n",
       "2004                 0.156656\n",
       "2005                 0.120683\n",
       "2006                 0.256414\n",
       "2007                 0.000000\n",
       "2008                 0.044686\n",
       "2009                -0.254350\n",
       "2010                -0.084895\n",
       "2011                 0.143128\n",
       "2012                 0.198579\n",
       "2013                 0.134284\n",
       "2014                 0.194389\n",
       "2015                 0.211146\n",
       "2016                 0.145626\n",
       "2017                 0.113280\n",
       "2018                 0.168774\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will get convergence warnings\n",
    "# They are due to difficulty converging\n",
    "# We can address this by accepting some error\n",
    "# with our qc_tol\n",
    "# See below\n",
    "fit_logit_reg = sm.Logit(y_train, x_train_std\n",
    "                        ).fit_regularized(alpha = 1/best['C'],\n",
    "                                          L1_wt = best['l1_ratio'],\n",
    "                                          qc_tol = 1e3)\n",
    "fit_logit_reg.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****************\n",
    "## Logit Prediction Diagnostics\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "Here we are going to look at how to produce\n",
    "\n",
    "- accuracy\n",
    "- visualizing optimal threshold values\n",
    "- the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    16709.000000\n",
       "mean         0.562992\n",
       "std          0.199280\n",
       "min          0.000559\n",
       "25%          0.435836\n",
       "50%          0.597314\n",
       "75%          0.712688\n",
       "max          0.999840\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logit.predict(x_test).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the summary of `yhat`, `statsmodels` predicts the probabilities. **How do we know that to be true?**\n",
    "\n",
    "***\n",
    "\n",
    "To produce the **prediction** diagnostics, it is easier to use `sklearn`. \n",
    "\n",
    "********\n",
    "### Logit Null Model\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "In classification, the **null model** is simply predicting the most frequently occuring class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    18754\n",
       "0.0    14664\n",
       "Name: pos_net_jobs, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562391525525166"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_logit_null = np.mean(y_test == 1)\n",
    "acc_logit_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "### Logit Full Model\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "For the sake of exposition, we are simply going to use all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_logit_sk = lm.LogisticRegression().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = fit_logit_sk.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562391525525166"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_logit = np.mean(yhat == y_test)\n",
    "acc_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(acc_logit - acc_logit_null)/acc_logit_null*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(fit_logit_sk, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may have to consider changing thresholds.\n",
    "\n",
    "***\n",
    "### Alternative Thresholds\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We can use `sklearn` to predict probabilities. \n",
    "It will produce a column for each class you have.\n",
    "In this case, we have two classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43727221, 0.56272779],\n",
       "       [0.42788686, 0.57211314],\n",
       "       [0.43320042, 0.56679958],\n",
       "       [0.45279396, 0.54720604],\n",
       "       [0.43947118, 0.56052882]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_proba = fit_logit_sk.predict_proba(x_test)\n",
    "yhat_proba[range(5), ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5186664255680362"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(yhat_proba[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The minimum probability of being in a county with positive net job creation is greater than the default threshold of 50%! Indeed! We will have to cross-validate the threshold.\n",
    "\n",
    "There is no built in function to cross-validate the threshold for logit. \n",
    "We will have to manually set up the loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(y_train, x_train, left_index = True, right_index = True)\n",
    "kf = KFold(n_splits = 5, random_state = 490, shuffle = True)\n",
    "alpha = np.round(    np.arange(0.5, 0.7, step = 0.01), 2    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [00:15<00:00,  1.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0.5: 0.5890237007303382,\n",
       " 0.51: 0.5933327978409808,\n",
       " 0.52: 0.5981805796624123,\n",
       " 0.53: 0.6037165631814263,\n",
       " 0.54: 0.6054819014778245,\n",
       " 0.55: 0.6013224153785524,\n",
       " 0.56: 0.5841161595742137,\n",
       " 0.57: 0.5613143176237966,\n",
       " 0.58: 0.5409958214582531,\n",
       " 0.59: 0.5271705372107636,\n",
       " 0.6: 0.5145423022392266,\n",
       " 0.61: 0.5055649251792713,\n",
       " 0.62: 0.4992807433278593,\n",
       " 0.63: 0.493415602151748,\n",
       " 0.64: 0.4865929863217523,\n",
       " 0.65: 0.48087755465894916,\n",
       " 0.66: 0.4772866530859359,\n",
       " 0.67: 0.47414464723008515,\n",
       " 0.68: 0.47028453986118207,\n",
       " 0.69: 0.46714254296005314}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = {}\n",
    "\n",
    "for a in tqdm(alpha):\n",
    "    acc = []\n",
    "    for trn, tst in kf.split(train):\n",
    "        yhat = (lm.LogisticRegression(solver = 'liblinear'\n",
    "                                      ).fit(train.iloc[trn, 1:], train.iloc[trn, 0]\n",
    "                                           ).predict_proba(train.iloc[tst, 1:])[:, 1] > a)*1\n",
    "        acc.append(np.mean(yhat == train.iloc[tst, 0]))\n",
    "    accuracy[a] = np.mean(acc)\n",
    "    \n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max accuracy at alpha = 0.54\n"
     ]
    }
   ],
   "source": [
    "print('max accuracy at alpha = %s' % max(accuracy, key = accuracy.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(accuracy.keys(), accuracy.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum is $\\alpha=0.54$. However, from the figure, it looks like we can choose either 0.54 or 0.55. Since the accuracy drops off quickly to the right, we may be safer using 0.54.\n",
    "\n",
    "Because we have adjusted the threshold, we need to manually calculate the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 157 7155]\n",
      " [ 122 9275]]\n",
      "0.5644862050392004\n",
      "0.5644862050392004 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_alpha = max(accuracy, key = accuracy.get)\n",
    "yhat_class = (yhat_proba[:, 1] >= best_alpha)*1\n",
    "\n",
    "TN = sum(((y_test == yhat_class) & (y_test == 0))*1)\n",
    "FP = sum(((y_test != yhat_class) & (y_test == 0))*1)\n",
    "FN = sum(((y_test != yhat_class) & (y_test == 1))*1)\n",
    "TP = sum(((y_test == yhat_class) & (y_test == 1))*1)\n",
    "\n",
    "print(np.array([[TN, FP],[FN, TP]]))\n",
    "print((TN + TP)/(TN + FN + FP + TP))\n",
    "acc_logit_54 = np.mean(yhat_class == y_test)\n",
    "print(acc_logit_54, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can compute the percent improvement from the null model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(  (acc_logit_54 - acc_logit_null)/acc_logit_null*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks we have improved our prediction by just over 8%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************\n",
    "# Multinomial Logistic Regression \n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We need to adjust features and labels to retreive our multiclass label. It is easier to start from scratch. \n",
    "\n",
    "Because logisitc functions struggle with many dummy variables, we are going to simply drop the fixed effects.\n",
    "\n",
    "We will be converting the categorical label to a `category` type of object prior to splitting. This is to ensure consistent labels in the training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 50127 entries, (1001, 2002) to (56045, 2018)\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   GeoName            50127 non-null  object  \n",
      " 1   pct_d_rgdp         50127 non-null  float64 \n",
      " 2   urate_bin          50127 non-null  category\n",
      " 3   pos_net_jobs       50127 non-null  int32   \n",
      " 4   emp_estabs         50127 non-null  float64 \n",
      " 5   estabs_entry_rate  50127 non-null  float64 \n",
      " 6   estabs_exit_rate   50127 non-null  float64 \n",
      " 7   pop                50127 non-null  float64 \n",
      " 8   pop_pct_black      50127 non-null  float64 \n",
      " 9   pop_pct_hisp       50127 non-null  float64 \n",
      " 10  lfpr               50127 non-null  float64 \n",
      " 11  density            50127 non-null  float64 \n",
      "dtypes: category(1), float64(9), int32(1), object(1)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_prepped = df.drop(columns = 'year')\n",
    "df_prepped['urate_bin'] = df_prepped['urate_bin'].astype('category')\n",
    "df_prepped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips  year\n",
       "1001  2002     lower\n",
       "      2003     lower\n",
       "      2004     lower\n",
       "      2005    higher\n",
       "      2006    higher\n",
       "Name: urate_bin, dtype: category\n",
       "Categories (3, object): ['higher', 'lower', 'similar']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepped['urate_bin'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips  year\n",
       "1001  2002    1\n",
       "      2003    1\n",
       "      2004    1\n",
       "      2005    0\n",
       "      2006    0\n",
       "dtype: int8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepped['urate_bin'].cat.codes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['urate_bin']\n",
    "x = df_prepped.drop(columns = ['urate_bin', 'GeoName'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************\n",
    "## MN Logit Inference\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.903926\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "fit_mnlogit = sm.MNLogit(y_train, x_train).fit(maxiter = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>             <td>MNLogit</td>     <td>Pseudo R-squared:</td>    <td>0.131</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>urate_bin</td>          <td>AIC:</td>        <td>60458.7757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 14:29</td>       <td>BIC:</td>        <td>60643.9464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33418</td>       <td>Log-Likelihood:</td>    <td>-30207.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>20</td>            <td>LL-Null:</td>        <td>-34744.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33396</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 0</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>-8.3683</td>  <td>0.1672</td>  <td>-50.0637</td> <td>0.0000</td> <td>-8.6959</td> <td>-8.0407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>0.0072</td>   <td>0.0016</td>   <td>4.4722</td>  <td>0.0000</td> <td>0.0040</td>  <td>0.0103</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>0.1640</td>   <td>0.0295</td>   <td>5.5591</td>  <td>0.0000</td> <td>0.1062</td>  <td>0.2218</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>0.0171</td>   <td>0.0033</td>   <td>5.1468</td>  <td>0.0000</td> <td>0.0106</td>  <td>0.0236</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>-0.0323</td>  <td>0.0054</td>   <td>-5.9356</td> <td>0.0000</td> <td>-0.0429</td> <td>-0.0216</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>-0.0973</td>  <td>0.0066</td>  <td>-14.7237</td> <td>0.0000</td> <td>-0.1103</td> <td>-0.0844</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>0.0000</td>   <td>0.0000</td>   <td>1.7132</td>  <td>0.0867</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>-0.0155</td>  <td>0.0013</td>  <td>-11.6562</td> <td>0.0000</td> <td>-0.0181</td> <td>-0.0129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>0.0134</td>   <td>0.0011</td>   <td>12.4767</td> <td>0.0000</td> <td>0.0113</td>  <td>0.0155</td> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>0.1174</td>   <td>0.0018</td>   <td>64.2527</td> <td>0.0000</td> <td>0.1138</td>  <td>0.1210</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>0.0000</td>   <td>0.0000</td>   <td>1.6576</td>  <td>0.0974</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 1</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>-2.5876</td>  <td>0.1636</td>  <td>-15.8190</td> <td>0.0000</td> <td>-2.9082</td> <td>-2.2670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>0.0003</td>   <td>0.0019</td>   <td>0.1329</td>  <td>0.8943</td> <td>-0.0036</td> <td>0.0041</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>0.0684</td>   <td>0.0328</td>   <td>2.0866</td>  <td>0.0369</td> <td>0.0042</td>  <td>0.1327</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>0.0348</td>   <td>0.0035</td>   <td>9.9104</td>  <td>0.0000</td> <td>0.0280</td>  <td>0.0417</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>-0.0460</td>  <td>0.0063</td>   <td>-7.2651</td> <td>0.0000</td> <td>-0.0584</td> <td>-0.0336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>-0.0642</td>  <td>0.0074</td>   <td>-8.6752</td> <td>0.0000</td> <td>-0.0788</td> <td>-0.0497</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>0.0000</td>   <td>0.0000</td>   <td>3.9790</td>  <td>0.0001</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>-0.0105</td>  <td>0.0012</td>   <td>-8.8689</td> <td>0.0000</td> <td>-0.0128</td> <td>-0.0081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>0.0008</td>   <td>0.0013</td>   <td>0.6447</td>  <td>0.5191</td> <td>-0.0017</td> <td>0.0034</td> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>0.0311</td>   <td>0.0018</td>   <td>16.9901</td> <td>0.0000</td> <td>0.0275</td>  <td>0.0347</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>0.0000</td>   <td>0.0000</td>   <td>1.8560</td>  <td>0.0634</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: MNLogit\n",
       "==================================================================\n",
       "Model:               MNLogit          Pseudo R-squared: 0.131     \n",
       "Dependent Variable:  urate_bin        AIC:              60458.7757\n",
       "Date:                2021-03-02 14:29 BIC:              60643.9464\n",
       "No. Observations:    33418            Log-Likelihood:   -30207.   \n",
       "Df Model:            20               LL-Null:          -34744.   \n",
       "Df Residuals:        33396            LLR p-value:      0.0000    \n",
       "Converged:           1.0000           Scale:            1.0000    \n",
       "No. Iterations:      6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 0    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const -8.3683   0.1672 -50.0637 0.0000 -8.6959 -8.0407\n",
       "       pct_d_rgdp  0.0072   0.0016   4.4722 0.0000  0.0040  0.0103\n",
       "     pos_net_jobs  0.1640   0.0295   5.5591 0.0000  0.1062  0.2218\n",
       "       emp_estabs  0.0171   0.0033   5.1468 0.0000  0.0106  0.0236\n",
       "estabs_entry_rate -0.0323   0.0054  -5.9356 0.0000 -0.0429 -0.0216\n",
       " estabs_exit_rate -0.0973   0.0066 -14.7237 0.0000 -0.1103 -0.0844\n",
       "              pop  0.0000   0.0000   1.7132 0.0867 -0.0000  0.0000\n",
       "    pop_pct_black -0.0155   0.0013 -11.6562 0.0000 -0.0181 -0.0129\n",
       "     pop_pct_hisp  0.0134   0.0011  12.4767 0.0000  0.0113  0.0155\n",
       "             lfpr  0.1174   0.0018  64.2527 0.0000  0.1138  0.1210\n",
       "          density  0.0000   0.0000   1.6576 0.0974 -0.0000  0.0000\n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 1    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const -2.5876   0.1636 -15.8190 0.0000 -2.9082 -2.2670\n",
       "       pct_d_rgdp  0.0003   0.0019   0.1329 0.8943 -0.0036  0.0041\n",
       "     pos_net_jobs  0.0684   0.0328   2.0866 0.0369  0.0042  0.1327\n",
       "       emp_estabs  0.0348   0.0035   9.9104 0.0000  0.0280  0.0417\n",
       "estabs_entry_rate -0.0460   0.0063  -7.2651 0.0000 -0.0584 -0.0336\n",
       " estabs_exit_rate -0.0642   0.0074  -8.6752 0.0000 -0.0788 -0.0497\n",
       "              pop  0.0000   0.0000   3.9790 0.0001  0.0000  0.0000\n",
       "    pop_pct_black -0.0105   0.0012  -8.8689 0.0000 -0.0128 -0.0081\n",
       "     pop_pct_hisp  0.0008   0.0013   0.6447 0.5191 -0.0017  0.0034\n",
       "             lfpr  0.0311   0.0018  16.9901 0.0000  0.0275  0.0347\n",
       "          density  0.0000   0.0000   1.8560 0.0634 -0.0000  0.0000\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mnlogit.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['higher', 'lower', 'similar'], dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the baseline class is 2, which is `similar`.\n",
    "\n",
    "We can change the category levels if we wish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.903926\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>             <td>MNLogit</td>     <td>Pseudo R-squared:</td>    <td>0.131</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>     <td>urate_bin</td>          <td>AIC:</td>        <td>60458.7757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-02 14:29</td>       <td>BIC:</td>        <td>60643.9464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33418</td>       <td>Log-Likelihood:</td>    <td>-30207.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>20</td>            <td>LL-Null:</td>        <td>-34744.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33396</td>        <td>LLR p-value:</td>      <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>Converged:</td>           <td>1.0000</td>           <td>Scale:</td>         <td>1.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>No. Iterations:</td>        <td>6.0000</td>              <td></td>               <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 0</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>5.7807</td>   <td>0.1909</td>   <td>30.2756</td> <td>0.0000</td> <td>5.4065</td>  <td>6.1549</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>-0.0069</td>  <td>0.0020</td>   <td>-3.5133</td> <td>0.0004</td> <td>-0.0108</td> <td>-0.0031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>-0.0956</td>  <td>0.0347</td>   <td>-2.7529</td> <td>0.0059</td> <td>-0.1636</td> <td>-0.0275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>0.0178</td>   <td>0.0036</td>   <td>4.8653</td>  <td>0.0000</td> <td>0.0106</td>  <td>0.0249</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>-0.0137</td>  <td>0.0067</td>   <td>-2.0400</td> <td>0.0413</td> <td>-0.0269</td> <td>-0.0005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>0.0331</td>   <td>0.0081</td>   <td>4.1048</td>  <td>0.0000</td> <td>0.0173</td>  <td>0.0489</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>0.0000</td>   <td>0.0000</td>   <td>2.4715</td>  <td>0.0135</td> <td>0.0000</td>  <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>0.0051</td>   <td>0.0015</td>   <td>3.2881</td>  <td>0.0010</td> <td>0.0021</td>  <td>0.0081</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>-0.0126</td>  <td>0.0013</td>   <td>-9.5398</td> <td>0.0000</td> <td>-0.0152</td> <td>-0.0100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>-0.0863</td>  <td>0.0021</td>  <td>-42.0772</td> <td>0.0000</td> <td>-0.0903</td> <td>-0.0823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>0.0000</td>   <td>0.0000</td>   <td>0.2169</td>  <td>0.8283</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <th>urate_bin = 1</th>    <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "        <td>const</td>       <td>8.3683</td>   <td>0.1672</td>   <td>50.0637</td> <td>0.0000</td> <td>8.0407</td>  <td>8.6959</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>pct_d_rgdp</td>     <td>-0.0072</td>  <td>0.0016</td>   <td>-4.4722</td> <td>0.0000</td> <td>-0.0103</td> <td>-0.0040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pos_net_jobs</td>    <td>-0.1640</td>  <td>0.0295</td>   <td>-5.5591</td> <td>0.0000</td> <td>-0.2218</td> <td>-0.1062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>emp_estabs</td>     <td>-0.0171</td>  <td>0.0033</td>   <td>-5.1468</td> <td>0.0000</td> <td>-0.0236</td> <td>-0.0106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_entry_rate</td> <td>0.0323</td>   <td>0.0054</td>   <td>5.9356</td>  <td>0.0000</td> <td>0.0216</td>  <td>0.0429</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>estabs_exit_rate</td>  <td>0.0973</td>   <td>0.0066</td>   <td>14.7237</td> <td>0.0000</td> <td>0.0844</td>  <td>0.1103</td> \n",
       "</tr>\n",
       "<tr>\n",
       "         <td>pop</td>        <td>-0.0000</td>  <td>0.0000</td>   <td>-1.7132</td> <td>0.0867</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_black</td>   <td>0.0155</td>   <td>0.0013</td>   <td>11.6562</td> <td>0.0000</td> <td>0.0129</td>  <td>0.0181</td> \n",
       "</tr>\n",
       "<tr>\n",
       "    <td>pop_pct_hisp</td>    <td>-0.0134</td>  <td>0.0011</td>  <td>-12.4767</td> <td>0.0000</td> <td>-0.0155</td> <td>-0.0113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "        <td>lfpr</td>        <td>-0.1174</td>  <td>0.0018</td>  <td>-64.2527</td> <td>0.0000</td> <td>-0.1210</td> <td>-0.1138</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>density</td>      <td>-0.0000</td>  <td>0.0000</td>   <td>-1.6576</td> <td>0.0974</td> <td>-0.0000</td> <td>0.0000</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                         Results: MNLogit\n",
       "==================================================================\n",
       "Model:               MNLogit          Pseudo R-squared: 0.131     \n",
       "Dependent Variable:  urate_bin        AIC:              60458.7757\n",
       "Date:                2021-03-02 14:29 BIC:              60643.9464\n",
       "No. Observations:    33418            Log-Likelihood:   -30207.   \n",
       "Df Model:            20               LL-Null:          -34744.   \n",
       "Df Residuals:        33396            LLR p-value:      0.0000    \n",
       "Converged:           1.0000           Scale:            1.0000    \n",
       "No. Iterations:      6.0000                                       \n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 0    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const  5.7807   0.1909  30.2756 0.0000  5.4065  6.1549\n",
       "       pct_d_rgdp -0.0069   0.0020  -3.5133 0.0004 -0.0108 -0.0031\n",
       "     pos_net_jobs -0.0956   0.0347  -2.7529 0.0059 -0.1636 -0.0275\n",
       "       emp_estabs  0.0178   0.0036   4.8653 0.0000  0.0106  0.0249\n",
       "estabs_entry_rate -0.0137   0.0067  -2.0400 0.0413 -0.0269 -0.0005\n",
       " estabs_exit_rate  0.0331   0.0081   4.1048 0.0000  0.0173  0.0489\n",
       "              pop  0.0000   0.0000   2.4715 0.0135  0.0000  0.0000\n",
       "    pop_pct_black  0.0051   0.0015   3.2881 0.0010  0.0021  0.0081\n",
       "     pop_pct_hisp -0.0126   0.0013  -9.5398 0.0000 -0.0152 -0.0100\n",
       "             lfpr -0.0863   0.0021 -42.0772 0.0000 -0.0903 -0.0823\n",
       "          density  0.0000   0.0000   0.2169 0.8283 -0.0000  0.0000\n",
       "------------------------------------------------------------------\n",
       "  urate_bin = 1    Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "------------------------------------------------------------------\n",
       "            const  8.3683   0.1672  50.0637 0.0000  8.0407  8.6959\n",
       "       pct_d_rgdp -0.0072   0.0016  -4.4722 0.0000 -0.0103 -0.0040\n",
       "     pos_net_jobs -0.1640   0.0295  -5.5591 0.0000 -0.2218 -0.1062\n",
       "       emp_estabs -0.0171   0.0033  -5.1468 0.0000 -0.0236 -0.0106\n",
       "estabs_entry_rate  0.0323   0.0054   5.9356 0.0000  0.0216  0.0429\n",
       " estabs_exit_rate  0.0973   0.0066  14.7237 0.0000  0.0844  0.1103\n",
       "              pop -0.0000   0.0000  -1.7132 0.0867 -0.0000  0.0000\n",
       "    pop_pct_black  0.0155   0.0013  11.6562 0.0000  0.0129  0.0181\n",
       "     pop_pct_hisp -0.0134   0.0011 -12.4767 0.0000 -0.0155 -0.0113\n",
       "             lfpr -0.1174   0.0018 -64.2527 0.0000 -0.1210 -0.1138\n",
       "          density -0.0000   0.0000  -1.6576 0.0974 -0.0000  0.0000\n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mnlogit = sm.MNLogit(y_train.cat.set_categories(new_categories = ['lower', 'similar', 'higher']),\n",
    "                                                    x_train).fit(maxiter = 150)\n",
    "fit_mnlogit.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********\n",
    "### MN Logit Marginal Effects\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>MNLogit Marginal Effects</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th> <td>urate_bin</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>          <td>dydx</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>At:</th>             <td>overall</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <th>urate_bin=lower</th>     <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>    0.0013</td> <td>    0.000</td> <td>    4.821</td> <td> 0.000</td> <td>    0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>    0.0257</td> <td>    0.005</td> <td>    5.158</td> <td> 0.000</td> <td>    0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>    0.0009</td> <td>    0.001</td> <td>    1.687</td> <td> 0.092</td> <td>   -0.000</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>   -0.0030</td> <td>    0.001</td> <td>   -3.221</td> <td> 0.001</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>   -0.0138</td> <td>    0.001</td> <td>  -12.196</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td> 2.883e-09</td> <td> 7.59e-09</td> <td>    0.380</td> <td> 0.704</td> <td> -1.2e-08</td> <td> 1.78e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>   -0.0022</td> <td>    0.000</td> <td>   -9.258</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>    0.0024</td> <td>    0.000</td> <td>   13.395</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>    0.0195</td> <td>    0.000</td> <td>   82.444</td> <td> 0.000</td> <td>    0.019</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td> 1.585e-06</td> <td> 1.33e-06</td> <td>    1.192</td> <td> 0.233</td> <td>-1.02e-06</td> <td> 4.19e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urate_bin=similar</th>    <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>   -0.0004</td> <td>    0.000</td> <td>   -1.590</td> <td> 0.112</td> <td>   -0.001</td> <td> 9.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>   -0.0004</td> <td>    0.004</td> <td>   -0.082</td> <td> 0.935</td> <td>   -0.009</td> <td>    0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>    0.0040</td> <td>    0.000</td> <td>    8.686</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>   -0.0047</td> <td>    0.001</td> <td>   -5.418</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>   -0.0032</td> <td>    0.001</td> <td>   -3.202</td> <td> 0.001</td> <td>   -0.005</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td> 2.339e-08</td> <td> 6.01e-09</td> <td>    3.891</td> <td> 0.000</td> <td> 1.16e-08</td> <td> 3.52e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>   -0.0005</td> <td>    0.000</td> <td>   -3.189</td> <td> 0.001</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>   -0.0007</td> <td>    0.000</td> <td>   -4.183</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>   -0.0029</td> <td>    0.000</td> <td>  -13.336</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td> 1.425e-06</td> <td> 1.04e-06</td> <td>    1.368</td> <td> 0.171</td> <td>-6.16e-07</td> <td> 3.47e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>urate_bin=higher</th>     <th>dy/dx</th>    <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pct_d_rgdp</th>        <td>   -0.0009</td> <td>    0.000</td> <td>   -2.974</td> <td> 0.003</td> <td>   -0.001</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>   -0.0254</td> <td>    0.005</td> <td>   -4.858</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>   -0.0049</td> <td>    0.001</td> <td>   -8.464</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>    0.0077</td> <td>    0.001</td> <td>    7.943</td> <td> 0.000</td> <td>    0.006</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>    0.0170</td> <td>    0.001</td> <td>   14.858</td> <td> 0.000</td> <td>    0.015</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>-2.627e-08</td> <td> 8.82e-09</td> <td>   -2.979</td> <td> 0.003</td> <td>-4.36e-08</td> <td>-8.98e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_black</th>     <td>    0.0027</td> <td>    0.000</td> <td>   13.314</td> <td> 0.000</td> <td>    0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>   -0.0017</td> <td>    0.000</td> <td>   -8.535</td> <td> 0.000</td> <td>   -0.002</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>   -0.0167</td> <td>    0.000</td> <td>  -66.917</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td> -3.01e-06</td> <td> 1.54e-06</td> <td>   -1.955</td> <td> 0.051</td> <td>-6.03e-06</td> <td> 7.48e-09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "       MNLogit Marginal Effects      \n",
       "=====================================\n",
       "Dep. Variable:              urate_bin\n",
       "Method:                          dydx\n",
       "At:                           overall\n",
       "=====================================================================================\n",
       "  urate_bin=lower      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp            0.0013      0.000      4.821      0.000       0.001       0.002\n",
       "pos_net_jobs          0.0257      0.005      5.158      0.000       0.016       0.036\n",
       "emp_estabs            0.0009      0.001      1.687      0.092      -0.000       0.002\n",
       "estabs_entry_rate    -0.0030      0.001     -3.221      0.001      -0.005      -0.001\n",
       "estabs_exit_rate     -0.0138      0.001    -12.196      0.000      -0.016      -0.012\n",
       "pop                2.883e-09   7.59e-09      0.380      0.704    -1.2e-08    1.78e-08\n",
       "pop_pct_black        -0.0022      0.000     -9.258      0.000      -0.003      -0.002\n",
       "pop_pct_hisp          0.0024      0.000     13.395      0.000       0.002       0.003\n",
       "lfpr                  0.0195      0.000     82.444      0.000       0.019       0.020\n",
       "density            1.585e-06   1.33e-06      1.192      0.233   -1.02e-06    4.19e-06\n",
       "-------------------------------------------------------------------------------------\n",
       "urate_bin=similar      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           -0.0004      0.000     -1.590      0.112      -0.001    9.68e-05\n",
       "pos_net_jobs         -0.0004      0.004     -0.082      0.935      -0.009       0.008\n",
       "emp_estabs            0.0040      0.000      8.686      0.000       0.003       0.005\n",
       "estabs_entry_rate    -0.0047      0.001     -5.418      0.000      -0.006      -0.003\n",
       "estabs_exit_rate     -0.0032      0.001     -3.202      0.001      -0.005      -0.001\n",
       "pop                2.339e-08   6.01e-09      3.891      0.000    1.16e-08    3.52e-08\n",
       "pop_pct_black        -0.0005      0.000     -3.189      0.001      -0.001      -0.000\n",
       "pop_pct_hisp         -0.0007      0.000     -4.183      0.000      -0.001      -0.000\n",
       "lfpr                 -0.0029      0.000    -13.336      0.000      -0.003      -0.002\n",
       "density            1.425e-06   1.04e-06      1.368      0.171   -6.16e-07    3.47e-06\n",
       "-------------------------------------------------------------------------------------\n",
       " urate_bin=higher      dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "pct_d_rgdp           -0.0009      0.000     -2.974      0.003      -0.001      -0.000\n",
       "pos_net_jobs         -0.0254      0.005     -4.858      0.000      -0.036      -0.015\n",
       "emp_estabs           -0.0049      0.001     -8.464      0.000      -0.006      -0.004\n",
       "estabs_entry_rate     0.0077      0.001      7.943      0.000       0.006       0.010\n",
       "estabs_exit_rate      0.0170      0.001     14.858      0.000       0.015       0.019\n",
       "pop               -2.627e-08   8.82e-09     -2.979      0.003   -4.36e-08   -8.98e-09\n",
       "pop_pct_black         0.0027      0.000     13.314      0.000       0.002       0.003\n",
       "pop_pct_hisp         -0.0017      0.000     -8.535      0.000      -0.002      -0.001\n",
       "lfpr                 -0.0167      0.000    -66.917      0.000      -0.017      -0.016\n",
       "density            -3.01e-06   1.54e-06     -1.955      0.051   -6.03e-06    7.48e-09\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_mnlogit.get_margeff().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*************\n",
    "### MN Logit Regularization \n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.01, 'l1_ratio': 0.9}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.arange(-5, -1, step = 1),\n",
    "    'l1_ratio':  np.arange(0, 1, step = 0.1)\n",
    "}\n",
    "\n",
    "lr_cv = lm.LogisticRegression(penalty = 'elasticnet', solver = 'saga',\n",
    "                              max_iter = 1e3, random_state = 490)\n",
    "grid_search = GridSearchCV(lr_cv, param_grid, \n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy',\n",
    "                          n_jobs = 10)\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best = grid_search.best_params_\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $C = \\frac{1}{\\alpha}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 0.9163228046383791\n",
      "            Iterations: 46\n",
      "            Function evaluations: 47\n",
      "            Gradient evaluations: 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-0.218634</td>\n",
       "      <td>-0.747939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pct_d_rgdp</th>\n",
       "      <td>0.047803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_net_jobs</th>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_estabs</th>\n",
       "      <td>0.056787</td>\n",
       "      <td>0.139618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estabs_entry_rate</th>\n",
       "      <td>-0.063320</td>\n",
       "      <td>-0.095805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estabs_exit_rate</th>\n",
       "      <td>-0.229619</td>\n",
       "      <td>-0.142851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>0.007940</td>\n",
       "      <td>0.044575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_pct_black</th>\n",
       "      <td>-0.185751</td>\n",
       "      <td>-0.120879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_pct_hisp</th>\n",
       "      <td>0.156680</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfpr</th>\n",
       "      <td>1.242667</td>\n",
       "      <td>0.315184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.004504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0         1\n",
       "const             -0.218634 -0.747939\n",
       "pct_d_rgdp         0.047803  0.000000\n",
       "pos_net_jobs       0.056821  0.004691\n",
       "emp_estabs         0.056787  0.139618\n",
       "estabs_entry_rate -0.063320 -0.095805\n",
       "estabs_exit_rate  -0.229619 -0.142851\n",
       "pop                0.007940  0.044575\n",
       "pop_pct_black     -0.185751 -0.120879\n",
       "pop_pct_hisp       0.156680  0.000000\n",
       "lfpr               1.242667  0.315184\n",
       "density            0.001677  0.004504"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You will get convergence warnings\n",
    "# They are due to difficulty converging\n",
    "# We can address this by accepting some error\n",
    "# with our qc_tol\n",
    "# See below\n",
    "fit_logit_reg = sm.MNLogit(y_train, x_train_std\n",
    "                          ).fit_regularized(alpha = 1/best['C'],\n",
    "                                            L1_wt = best['l1_ratio'],\n",
    "                                            qc_tol = 1e3)\n",
    "fit_logit_reg.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, you can decide whether or not to keep variables if you wish to refit without regularization.\n",
    "As a rule of thumb, drop features that are 50% zero across classes.\n",
    "\n",
    "***\n",
    "## MN Logit Prediction Diagnostics\n",
    "[TOP](#Regression-Based-Classification)\n",
    "\n",
    "We will proceed as we did for the binomial logistic regression.\n",
    "We will first fit the null model and then compare it to another model.\n",
    "\n",
    "********\n",
    "### MN Logit Null Model\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "higher     14653\n",
       "lower      12665\n",
       "similar     6100\n",
       "Name: urate_bin, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the largest grouping of counties have much higher than national unemployment rates.\n",
    "We will predict that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4348554671135316"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_mnlogit_null = np.mean(y_test == 'higher')\n",
    "acc_mnlogit_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "### MN Logit Full Model\n",
    "[TOP](#Regression-Based-Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_mnlogit_sk = lm.LogisticRegression(solver = 'liblinear').fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x324 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(fit_mnlogit_sk, x_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we are having trouble predicting the county unemployment rate similar to the national.\n",
    "\n",
    "Let's take a look at the overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5456939373990065"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = fit_mnlogit_sk.predict(x_test)\n",
    "acc_mnlogit = np.mean(yhat == y_test)\n",
    "acc_mnlogit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.49"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(100*(acc_mnlogit - acc_mnlogit_null)/acc_mnlogit_null, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not a bad improvement, but remember that we are only getting it correct barely more than 50% of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
