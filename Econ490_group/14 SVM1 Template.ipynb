{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines - Part 1\n",
    "\n",
    "#### Table of Contents\n",
    "\n",
    "- [Preliminaries](#Preliminaries)\n",
    "- [Null Model](#Null-Model)\n",
    "- [10% Correlation](#10%-Correlation)\n",
    "- [5% Correlation](#5%-Correlation)\n",
    "- [1% Correlation](#1%-Correlation)\n",
    "- [Comparison](#Comparison)\n",
    "\n",
    "\n",
    "Take aways from this script:\n",
    "\n",
    "1. Copy and paste your code\n",
    "2. Regularization helps with weak predictors\n",
    "\n",
    "***\n",
    "# Preliminaries\n",
    "[TOP](#Support-Vector-Machines---Part-1)\n",
    "\n",
    "Here we have our usual set up.\n",
    "\n",
    "However, this time we are going to compare choosing features based upon their correlation with the label `pos_net_job`.\n",
    "We will do so at\n",
    "\n",
    "* 10%\n",
    "- 5%\n",
    "- 1%\n",
    "\n",
    "This will result with a postponed train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# processing\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#algorithms\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('C:/Users/hubst/Econ490_group/class_data.pkl')\n",
    "df_prepped = df.drop(columns = ['urate_bin', 'year', 'GeoName']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True),\n",
    "    pd.get_dummies(df['year'], drop_first = True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********\n",
    "# Null Model \n",
    "[TOP](#Support-Vector-Machines---Part-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['pos_net_jobs'].astype(float)\n",
    "y_train, y_test = train_test_split(y,\n",
    "                                  train_size = 2/3,\n",
    "                                  random_state = 490)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.562391525525166"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_null = y_train.value_counts().index[0]\n",
    "acc_null = np.mean(yhat_null == y_test)\n",
    "acc_null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# 10% Correlation\n",
    "[TOP](#Support-Vector-Machines---Part-1)\n",
    "\n",
    "First, let's produce a correlation matrix with the data frame method `.corr()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pct_d_rgdp</th>\n",
       "      <th>pos_net_jobs</th>\n",
       "      <th>emp_estabs</th>\n",
       "      <th>estabs_entry_rate</th>\n",
       "      <th>estabs_exit_rate</th>\n",
       "      <th>pop</th>\n",
       "      <th>pop_pct_black</th>\n",
       "      <th>pop_pct_hisp</th>\n",
       "      <th>lfpr</th>\n",
       "      <th>density</th>\n",
       "      <th>...</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pct_d_rgdp</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.095578</td>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.107552</td>\n",
       "      <td>-0.016574</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>-0.045466</td>\n",
       "      <td>0.042703</td>\n",
       "      <td>0.086249</td>\n",
       "      <td>-0.001632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075401</td>\n",
       "      <td>0.022368</td>\n",
       "      <td>0.001775</td>\n",
       "      <td>-0.018607</td>\n",
       "      <td>0.015269</td>\n",
       "      <td>-0.016142</td>\n",
       "      <td>-0.006248</td>\n",
       "      <td>-0.043309</td>\n",
       "      <td>-0.016039</td>\n",
       "      <td>0.009017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos_net_jobs</th>\n",
       "      <td>0.095578</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084148</td>\n",
       "      <td>0.169942</td>\n",
       "      <td>-0.142796</td>\n",
       "      <td>0.060543</td>\n",
       "      <td>-0.031478</td>\n",
       "      <td>0.062863</td>\n",
       "      <td>0.044032</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.204247</td>\n",
       "      <td>-0.119566</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>0.057530</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.035330</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.045474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emp_estabs</th>\n",
       "      <td>-0.020888</td>\n",
       "      <td>0.084148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.096189</td>\n",
       "      <td>-0.132596</td>\n",
       "      <td>0.265142</td>\n",
       "      <td>0.209641</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>-0.097833</td>\n",
       "      <td>0.145808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020331</td>\n",
       "      <td>-0.022647</td>\n",
       "      <td>-0.014737</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>0.019693</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>0.019925</td>\n",
       "      <td>0.029483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estabs_entry_rate</th>\n",
       "      <td>0.107552</td>\n",
       "      <td>0.169942</td>\n",
       "      <td>-0.096189</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378506</td>\n",
       "      <td>0.119729</td>\n",
       "      <td>-0.034320</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>0.059172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097782</td>\n",
       "      <td>-0.079984</td>\n",
       "      <td>-0.067017</td>\n",
       "      <td>-0.047806</td>\n",
       "      <td>-0.069377</td>\n",
       "      <td>-0.063668</td>\n",
       "      <td>-0.060740</td>\n",
       "      <td>-0.062557</td>\n",
       "      <td>-0.098154</td>\n",
       "      <td>-0.126031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>estabs_exit_rate</th>\n",
       "      <td>-0.016574</td>\n",
       "      <td>-0.142796</td>\n",
       "      <td>-0.132596</td>\n",
       "      <td>0.378506</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.083556</td>\n",
       "      <td>-0.025939</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>-0.041004</td>\n",
       "      <td>0.047255</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131820</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>-0.053665</td>\n",
       "      <td>-0.056253</td>\n",
       "      <td>-0.107329</td>\n",
       "      <td>-0.109617</td>\n",
       "      <td>-0.126360</td>\n",
       "      <td>-0.076538</td>\n",
       "      <td>-0.120902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop</th>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.060543</td>\n",
       "      <td>0.265142</td>\n",
       "      <td>0.119729</td>\n",
       "      <td>0.083556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.090054</td>\n",
       "      <td>0.198232</td>\n",
       "      <td>-0.005642</td>\n",
       "      <td>0.338012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.005365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_pct_black</th>\n",
       "      <td>-0.045466</td>\n",
       "      <td>-0.031478</td>\n",
       "      <td>0.209641</td>\n",
       "      <td>-0.034320</td>\n",
       "      <td>-0.025939</td>\n",
       "      <td>0.090054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088277</td>\n",
       "      <td>-0.420904</td>\n",
       "      <td>0.106843</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.007159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pop_pct_hisp</th>\n",
       "      <td>0.042703</td>\n",
       "      <td>0.062863</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>0.090729</td>\n",
       "      <td>0.059833</td>\n",
       "      <td>0.198232</td>\n",
       "      <td>-0.088277</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.044089</td>\n",
       "      <td>0.085918</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>0.018469</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>0.023543</td>\n",
       "      <td>0.026345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lfpr</th>\n",
       "      <td>0.086249</td>\n",
       "      <td>0.044032</td>\n",
       "      <td>-0.097833</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>-0.041004</td>\n",
       "      <td>-0.005642</td>\n",
       "      <td>-0.420904</td>\n",
       "      <td>-0.044089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>-0.019918</td>\n",
       "      <td>-0.024598</td>\n",
       "      <td>-0.024735</td>\n",
       "      <td>-0.019397</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.006658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>density</th>\n",
       "      <td>-0.001632</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>0.145808</td>\n",
       "      <td>0.059172</td>\n",
       "      <td>0.047255</td>\n",
       "      <td>0.338012</td>\n",
       "      <td>0.106843</td>\n",
       "      <td>0.085918</td>\n",
       "      <td>-0.012269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower</th>\n",
       "      <td>0.063624</td>\n",
       "      <td>0.054305</td>\n",
       "      <td>-0.038898</td>\n",
       "      <td>-0.040129</td>\n",
       "      <td>-0.101179</td>\n",
       "      <td>-0.007779</td>\n",
       "      <td>-0.227586</td>\n",
       "      <td>0.044422</td>\n",
       "      <td>0.436961</td>\n",
       "      <td>-0.007477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041785</td>\n",
       "      <td>0.028238</td>\n",
       "      <td>0.031943</td>\n",
       "      <td>0.025853</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.026865</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.029948</td>\n",
       "      <td>0.011283</td>\n",
       "      <td>0.019749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>similar</th>\n",
       "      <td>-0.015593</td>\n",
       "      <td>0.002937</td>\n",
       "      <td>0.076103</td>\n",
       "      <td>-0.033774</td>\n",
       "      <td>-0.028123</td>\n",
       "      <td>0.040705</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>-0.009442</td>\n",
       "      <td>-0.057839</td>\n",
       "      <td>0.018431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037756</td>\n",
       "      <td>-0.032640</td>\n",
       "      <td>-0.032081</td>\n",
       "      <td>-0.017441</td>\n",
       "      <td>-0.009465</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>0.022864</td>\n",
       "      <td>0.032695</td>\n",
       "      <td>0.064786</td>\n",
       "      <td>0.075636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.026497</td>\n",
       "      <td>0.021893</td>\n",
       "      <td>-0.007550</td>\n",
       "      <td>0.095816</td>\n",
       "      <td>0.051352</td>\n",
       "      <td>-0.005016</td>\n",
       "      <td>-0.004563</td>\n",
       "      <td>-0.025706</td>\n",
       "      <td>0.018352</td>\n",
       "      <td>-0.001642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062654</td>\n",
       "      <td>-0.062417</td>\n",
       "      <td>-0.062801</td>\n",
       "      <td>-0.062405</td>\n",
       "      <td>-0.062451</td>\n",
       "      <td>-0.062496</td>\n",
       "      <td>-0.062496</td>\n",
       "      <td>-0.062507</td>\n",
       "      <td>-0.062349</td>\n",
       "      <td>-0.062428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.052089</td>\n",
       "      <td>-0.005343</td>\n",
       "      <td>0.082476</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>-0.003948</td>\n",
       "      <td>-0.004974</td>\n",
       "      <td>-0.021539</td>\n",
       "      <td>0.010231</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062485</td>\n",
       "      <td>-0.062249</td>\n",
       "      <td>-0.062632</td>\n",
       "      <td>-0.062237</td>\n",
       "      <td>-0.062282</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.062328</td>\n",
       "      <td>-0.062339</td>\n",
       "      <td>-0.062181</td>\n",
       "      <td>-0.062260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.032065</td>\n",
       "      <td>-0.007540</td>\n",
       "      <td>0.114961</td>\n",
       "      <td>0.022964</td>\n",
       "      <td>-0.004217</td>\n",
       "      <td>-0.005299</td>\n",
       "      <td>-0.017229</td>\n",
       "      <td>0.014200</td>\n",
       "      <td>-0.001711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062755</td>\n",
       "      <td>-0.062517</td>\n",
       "      <td>-0.062902</td>\n",
       "      <td>-0.062506</td>\n",
       "      <td>-0.062551</td>\n",
       "      <td>-0.062597</td>\n",
       "      <td>-0.062597</td>\n",
       "      <td>-0.062608</td>\n",
       "      <td>-0.062449</td>\n",
       "      <td>-0.062529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.072158</td>\n",
       "      <td>0.097031</td>\n",
       "      <td>-0.001963</td>\n",
       "      <td>0.232712</td>\n",
       "      <td>0.126006</td>\n",
       "      <td>-0.003949</td>\n",
       "      <td>-0.005169</td>\n",
       "      <td>-0.012013</td>\n",
       "      <td>0.023355</td>\n",
       "      <td>-0.001756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063002</td>\n",
       "      <td>-0.062763</td>\n",
       "      <td>-0.063149</td>\n",
       "      <td>-0.062751</td>\n",
       "      <td>-0.062797</td>\n",
       "      <td>-0.062842</td>\n",
       "      <td>-0.062842</td>\n",
       "      <td>-0.062854</td>\n",
       "      <td>-0.062694</td>\n",
       "      <td>-0.062774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>-0.014979</td>\n",
       "      <td>-0.030403</td>\n",
       "      <td>-0.004551</td>\n",
       "      <td>0.107720</td>\n",
       "      <td>0.041441</td>\n",
       "      <td>-0.002016</td>\n",
       "      <td>-0.001986</td>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.013178</td>\n",
       "      <td>-0.000930</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062587</td>\n",
       "      <td>-0.062349</td>\n",
       "      <td>-0.062733</td>\n",
       "      <td>-0.062338</td>\n",
       "      <td>-0.062383</td>\n",
       "      <td>-0.062429</td>\n",
       "      <td>-0.062429</td>\n",
       "      <td>-0.062440</td>\n",
       "      <td>-0.062281</td>\n",
       "      <td>-0.062361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-0.032921</td>\n",
       "      <td>-0.037354</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>-0.014142</td>\n",
       "      <td>0.091066</td>\n",
       "      <td>-0.001513</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.005676</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>-0.000746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062688</td>\n",
       "      <td>-0.062450</td>\n",
       "      <td>-0.062835</td>\n",
       "      <td>-0.062439</td>\n",
       "      <td>-0.062484</td>\n",
       "      <td>-0.062529</td>\n",
       "      <td>-0.062529</td>\n",
       "      <td>-0.062541</td>\n",
       "      <td>-0.062382</td>\n",
       "      <td>-0.062461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-0.075401</td>\n",
       "      <td>-0.204247</td>\n",
       "      <td>-0.020331</td>\n",
       "      <td>-0.097782</td>\n",
       "      <td>0.131820</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>0.019472</td>\n",
       "      <td>-0.000227</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062226</td>\n",
       "      <td>-0.062609</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.062260</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>-0.062316</td>\n",
       "      <td>-0.062158</td>\n",
       "      <td>-0.062237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.022368</td>\n",
       "      <td>-0.119566</td>\n",
       "      <td>-0.022647</td>\n",
       "      <td>-0.079984</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>-0.000273</td>\n",
       "      <td>-0.017164</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062226</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062372</td>\n",
       "      <td>-0.061979</td>\n",
       "      <td>-0.062024</td>\n",
       "      <td>-0.062069</td>\n",
       "      <td>-0.062069</td>\n",
       "      <td>-0.062080</td>\n",
       "      <td>-0.061923</td>\n",
       "      <td>-0.062001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.001775</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>-0.014737</td>\n",
       "      <td>-0.067017</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>-0.020647</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062609</td>\n",
       "      <td>-0.062372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062360</td>\n",
       "      <td>-0.062406</td>\n",
       "      <td>-0.062451</td>\n",
       "      <td>-0.062451</td>\n",
       "      <td>-0.062462</td>\n",
       "      <td>-0.062304</td>\n",
       "      <td>-0.062383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>-0.018607</td>\n",
       "      <td>0.055287</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>-0.047806</td>\n",
       "      <td>-0.053665</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>-0.019918</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062215</td>\n",
       "      <td>-0.061979</td>\n",
       "      <td>-0.062360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062013</td>\n",
       "      <td>-0.062058</td>\n",
       "      <td>-0.062058</td>\n",
       "      <td>-0.062069</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>-0.061990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>0.015269</td>\n",
       "      <td>0.018699</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>-0.069377</td>\n",
       "      <td>-0.056253</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.009980</td>\n",
       "      <td>-0.024598</td>\n",
       "      <td>0.001047</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062260</td>\n",
       "      <td>-0.062024</td>\n",
       "      <td>-0.062406</td>\n",
       "      <td>-0.062013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062103</td>\n",
       "      <td>-0.062103</td>\n",
       "      <td>-0.062114</td>\n",
       "      <td>-0.061956</td>\n",
       "      <td>-0.062035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014</th>\n",
       "      <td>-0.016142</td>\n",
       "      <td>0.057530</td>\n",
       "      <td>0.010087</td>\n",
       "      <td>-0.063668</td>\n",
       "      <td>-0.107329</td>\n",
       "      <td>0.003024</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>0.012258</td>\n",
       "      <td>-0.024735</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>-0.062069</td>\n",
       "      <td>-0.062451</td>\n",
       "      <td>-0.062058</td>\n",
       "      <td>-0.062103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062148</td>\n",
       "      <td>-0.062159</td>\n",
       "      <td>-0.062001</td>\n",
       "      <td>-0.062080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015</th>\n",
       "      <td>-0.006248</td>\n",
       "      <td>0.070377</td>\n",
       "      <td>0.019693</td>\n",
       "      <td>-0.060740</td>\n",
       "      <td>-0.109617</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.018469</td>\n",
       "      <td>-0.019397</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062305</td>\n",
       "      <td>-0.062069</td>\n",
       "      <td>-0.062451</td>\n",
       "      <td>-0.062058</td>\n",
       "      <td>-0.062103</td>\n",
       "      <td>-0.062148</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062159</td>\n",
       "      <td>-0.062001</td>\n",
       "      <td>-0.062080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016</th>\n",
       "      <td>-0.043309</td>\n",
       "      <td>0.035330</td>\n",
       "      <td>0.016318</td>\n",
       "      <td>-0.062557</td>\n",
       "      <td>-0.126360</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.020371</td>\n",
       "      <td>-0.012369</td>\n",
       "      <td>0.001607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062316</td>\n",
       "      <td>-0.062080</td>\n",
       "      <td>-0.062462</td>\n",
       "      <td>-0.062069</td>\n",
       "      <td>-0.062114</td>\n",
       "      <td>-0.062159</td>\n",
       "      <td>-0.062159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062013</td>\n",
       "      <td>-0.062091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>-0.016039</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.019925</td>\n",
       "      <td>-0.098154</td>\n",
       "      <td>-0.076538</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.006433</td>\n",
       "      <td>0.023543</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062158</td>\n",
       "      <td>-0.061923</td>\n",
       "      <td>-0.062304</td>\n",
       "      <td>-0.061911</td>\n",
       "      <td>-0.061956</td>\n",
       "      <td>-0.062001</td>\n",
       "      <td>-0.062001</td>\n",
       "      <td>-0.062013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.061934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.045474</td>\n",
       "      <td>0.029483</td>\n",
       "      <td>-0.126031</td>\n",
       "      <td>-0.120902</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.026345</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.062237</td>\n",
       "      <td>-0.062001</td>\n",
       "      <td>-0.062383</td>\n",
       "      <td>-0.061990</td>\n",
       "      <td>-0.062035</td>\n",
       "      <td>-0.062080</td>\n",
       "      <td>-0.062080</td>\n",
       "      <td>-0.062091</td>\n",
       "      <td>-0.061934</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   pct_d_rgdp  pos_net_jobs  emp_estabs  estabs_entry_rate  \\\n",
       "pct_d_rgdp           1.000000      0.095578   -0.020888           0.107552   \n",
       "pos_net_jobs         0.095578      1.000000    0.084148           0.169942   \n",
       "emp_estabs          -0.020888      0.084148    1.000000          -0.096189   \n",
       "estabs_entry_rate    0.107552      0.169942   -0.096189           1.000000   \n",
       "estabs_exit_rate    -0.016574     -0.142796   -0.132596           0.378506   \n",
       "pop                  0.000396      0.060543    0.265142           0.119729   \n",
       "pop_pct_black       -0.045466     -0.031478    0.209641          -0.034320   \n",
       "pop_pct_hisp         0.042703      0.062863    0.046165           0.090729   \n",
       "lfpr                 0.086249      0.044032   -0.097833           0.008339   \n",
       "density             -0.001632      0.029483    0.145808           0.059172   \n",
       "lower                0.063624      0.054305   -0.038898          -0.040129   \n",
       "similar             -0.015593      0.002937    0.076103          -0.033774   \n",
       "2003                 0.026497      0.021893   -0.007550           0.095816   \n",
       "2004                 0.027821      0.052089   -0.005343           0.082476   \n",
       "2005                 0.017037      0.032065   -0.007540           0.114961   \n",
       "2006                 0.072158      0.097031   -0.001963           0.232712   \n",
       "2007                -0.014979     -0.030403   -0.004551           0.107720   \n",
       "2008                -0.032921     -0.037354   -0.000920          -0.014142   \n",
       "2009                -0.075401     -0.204247   -0.020331          -0.097782   \n",
       "2010                 0.022368     -0.119566   -0.022647          -0.079984   \n",
       "2011                 0.001775      0.005404   -0.014737          -0.067017   \n",
       "2012                -0.018607      0.055287   -0.000619          -0.047806   \n",
       "2013                 0.015269      0.018699    0.001938          -0.069377   \n",
       "2014                -0.016142      0.057530    0.010087          -0.063668   \n",
       "2015                -0.006248      0.070377    0.019693          -0.060740   \n",
       "2016                -0.043309      0.035330    0.016318          -0.062557   \n",
       "2017                -0.016039      0.005861    0.019925          -0.098154   \n",
       "2018                 0.009017      0.045474    0.029483          -0.126031   \n",
       "\n",
       "                   estabs_exit_rate       pop  pop_pct_black  pop_pct_hisp  \\\n",
       "pct_d_rgdp                -0.016574  0.000396      -0.045466      0.042703   \n",
       "pos_net_jobs              -0.142796  0.060543      -0.031478      0.062863   \n",
       "emp_estabs                -0.132596  0.265142       0.209641      0.046165   \n",
       "estabs_entry_rate          0.378506  0.119729      -0.034320      0.090729   \n",
       "estabs_exit_rate           1.000000  0.083556      -0.025939      0.059833   \n",
       "pop                        0.083556  1.000000       0.090054      0.198232   \n",
       "pop_pct_black             -0.025939  0.090054       1.000000     -0.088277   \n",
       "pop_pct_hisp               0.059833  0.198232      -0.088277      1.000000   \n",
       "lfpr                      -0.041004 -0.005642      -0.420904     -0.044089   \n",
       "density                    0.047255  0.338012       0.106843      0.085918   \n",
       "lower                     -0.101179 -0.007779      -0.227586      0.044422   \n",
       "similar                   -0.028123  0.040705       0.010951     -0.009442   \n",
       "2003                       0.051352 -0.005016      -0.004563     -0.025706   \n",
       "2004                       0.005419 -0.003948      -0.004974     -0.021539   \n",
       "2005                       0.022964 -0.004217      -0.005299     -0.017229   \n",
       "2006                       0.126006 -0.003949      -0.005169     -0.012013   \n",
       "2007                       0.041441 -0.002016      -0.001986     -0.009066   \n",
       "2008                       0.091066 -0.001513      -0.000625     -0.005676   \n",
       "2009                       0.131820 -0.000306      -0.000788     -0.000996   \n",
       "2010                       0.014639  0.000889      -0.000718     -0.000273   \n",
       "2011                       0.008815  0.000582       0.001806      0.003606   \n",
       "2012                      -0.053665  0.002071       0.001105      0.007185   \n",
       "2013                      -0.056253  0.002534       0.003142      0.009980   \n",
       "2014                      -0.107329  0.003024       0.004833      0.012258   \n",
       "2015                      -0.109617  0.003618       0.001927      0.018469   \n",
       "2016                      -0.126360  0.004200       0.004551      0.020371   \n",
       "2017                      -0.076538  0.005113       0.006433      0.023543   \n",
       "2018                      -0.120902  0.005365       0.007159      0.026345   \n",
       "\n",
       "                       lfpr   density  ...      2009      2010      2011  \\\n",
       "pct_d_rgdp         0.086249 -0.001632  ... -0.075401  0.022368  0.001775   \n",
       "pos_net_jobs       0.044032  0.029483  ... -0.204247 -0.119566  0.005404   \n",
       "emp_estabs        -0.097833  0.145808  ... -0.020331 -0.022647 -0.014737   \n",
       "estabs_entry_rate  0.008339  0.059172  ... -0.097782 -0.079984 -0.067017   \n",
       "estabs_exit_rate  -0.041004  0.047255  ...  0.131820  0.014639  0.008815   \n",
       "pop               -0.005642  0.338012  ... -0.000306  0.000889  0.000582   \n",
       "pop_pct_black     -0.420904  0.106843  ... -0.000788 -0.000718  0.001806   \n",
       "pop_pct_hisp      -0.044089  0.085918  ... -0.000996 -0.000273  0.003606   \n",
       "lfpr               1.000000 -0.012269  ...  0.019472 -0.017164 -0.020647   \n",
       "density           -0.012269  1.000000  ... -0.000227  0.000284  0.000175   \n",
       "lower              0.436961 -0.007477  ...  0.041785  0.028238  0.031943   \n",
       "similar           -0.057839  0.018431  ... -0.037756 -0.032640 -0.032081   \n",
       "2003               0.018352 -0.001642  ... -0.062654 -0.062417 -0.062801   \n",
       "2004               0.010231 -0.001322  ... -0.062485 -0.062249 -0.062632   \n",
       "2005               0.014200 -0.001711  ... -0.062755 -0.062517 -0.062902   \n",
       "2006               0.023355 -0.001756  ... -0.063002 -0.062763 -0.063149   \n",
       "2007               0.013178 -0.000930  ... -0.062587 -0.062349 -0.062733   \n",
       "2008               0.020799 -0.000746  ... -0.062688 -0.062450 -0.062835   \n",
       "2009               0.019472 -0.000227  ...  1.000000 -0.062226 -0.062609   \n",
       "2010              -0.017164  0.000284  ... -0.062226  1.000000 -0.062372   \n",
       "2011              -0.020647  0.000175  ... -0.062609 -0.062372  1.000000   \n",
       "2012              -0.019918  0.000864  ... -0.062215 -0.061979 -0.062360   \n",
       "2013              -0.024598  0.001047  ... -0.062260 -0.062024 -0.062406   \n",
       "2014              -0.024735  0.001222  ... -0.062305 -0.062069 -0.062451   \n",
       "2015              -0.019397  0.001427  ... -0.062305 -0.062069 -0.062451   \n",
       "2016              -0.012369  0.001607  ... -0.062316 -0.062080 -0.062462   \n",
       "2017              -0.007152  0.001920  ... -0.062158 -0.061923 -0.062304   \n",
       "2018               0.006658  0.001914  ... -0.062237 -0.062001 -0.062383   \n",
       "\n",
       "                       2012      2013      2014      2015      2016      2017  \\\n",
       "pct_d_rgdp        -0.018607  0.015269 -0.016142 -0.006248 -0.043309 -0.016039   \n",
       "pos_net_jobs       0.055287  0.018699  0.057530  0.070377  0.035330  0.005861   \n",
       "emp_estabs        -0.000619  0.001938  0.010087  0.019693  0.016318  0.019925   \n",
       "estabs_entry_rate -0.047806 -0.069377 -0.063668 -0.060740 -0.062557 -0.098154   \n",
       "estabs_exit_rate  -0.053665 -0.056253 -0.107329 -0.109617 -0.126360 -0.076538   \n",
       "pop                0.002071  0.002534  0.003024  0.003618  0.004200  0.005113   \n",
       "pop_pct_black      0.001105  0.003142  0.004833  0.001927  0.004551  0.006433   \n",
       "pop_pct_hisp       0.007185  0.009980  0.012258  0.018469  0.020371  0.023543   \n",
       "lfpr              -0.019918 -0.024598 -0.024735 -0.019397 -0.012369 -0.007152   \n",
       "density            0.000864  0.001047  0.001222  0.001427  0.001607  0.001920   \n",
       "lower              0.025853  0.026622  0.026865  0.030720  0.029948  0.011283   \n",
       "similar           -0.017441 -0.009465  0.010133  0.022864  0.032695  0.064786   \n",
       "2003              -0.062405 -0.062451 -0.062496 -0.062496 -0.062507 -0.062349   \n",
       "2004              -0.062237 -0.062282 -0.062328 -0.062328 -0.062339 -0.062181   \n",
       "2005              -0.062506 -0.062551 -0.062597 -0.062597 -0.062608 -0.062449   \n",
       "2006              -0.062751 -0.062797 -0.062842 -0.062842 -0.062854 -0.062694   \n",
       "2007              -0.062338 -0.062383 -0.062429 -0.062429 -0.062440 -0.062281   \n",
       "2008              -0.062439 -0.062484 -0.062529 -0.062529 -0.062541 -0.062382   \n",
       "2009              -0.062215 -0.062260 -0.062305 -0.062305 -0.062316 -0.062158   \n",
       "2010              -0.061979 -0.062024 -0.062069 -0.062069 -0.062080 -0.061923   \n",
       "2011              -0.062360 -0.062406 -0.062451 -0.062451 -0.062462 -0.062304   \n",
       "2012               1.000000 -0.062013 -0.062058 -0.062058 -0.062069 -0.061911   \n",
       "2013              -0.062013  1.000000 -0.062103 -0.062103 -0.062114 -0.061956   \n",
       "2014              -0.062058 -0.062103  1.000000 -0.062148 -0.062159 -0.062001   \n",
       "2015              -0.062058 -0.062103 -0.062148  1.000000 -0.062159 -0.062001   \n",
       "2016              -0.062069 -0.062114 -0.062159 -0.062159  1.000000 -0.062013   \n",
       "2017              -0.061911 -0.061956 -0.062001 -0.062001 -0.062013  1.000000   \n",
       "2018              -0.061990 -0.062035 -0.062080 -0.062080 -0.062091 -0.061934   \n",
       "\n",
       "                       2018  \n",
       "pct_d_rgdp         0.009017  \n",
       "pos_net_jobs       0.045474  \n",
       "emp_estabs         0.029483  \n",
       "estabs_entry_rate -0.126031  \n",
       "estabs_exit_rate  -0.120902  \n",
       "pop                0.005365  \n",
       "pop_pct_black      0.007159  \n",
       "pop_pct_hisp       0.026345  \n",
       "lfpr               0.006658  \n",
       "density            0.001914  \n",
       "lower              0.019749  \n",
       "similar            0.075636  \n",
       "2003              -0.062428  \n",
       "2004              -0.062260  \n",
       "2005              -0.062529  \n",
       "2006              -0.062774  \n",
       "2007              -0.062361  \n",
       "2008              -0.062461  \n",
       "2009              -0.062237  \n",
       "2010              -0.062001  \n",
       "2011              -0.062383  \n",
       "2012              -0.061990  \n",
       "2013              -0.062035  \n",
       "2014              -0.062080  \n",
       "2015              -0.062080  \n",
       "2016              -0.062091  \n",
       "2017              -0.061934  \n",
       "2018               1.000000  \n",
       "\n",
       "[28 rows x 28 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepped.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is far too much information. \n",
    "We reall only want the values for `pos_net_jobs`.\n",
    "\n",
    "Remember that Python is zero-indexed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pct_d_rgdp           0.095578\n",
       "pos_net_jobs         1.000000\n",
       "emp_estabs           0.084148\n",
       "estabs_entry_rate    0.169942\n",
       "estabs_exit_rate    -0.142796\n",
       "pop                  0.060543\n",
       "pop_pct_black       -0.031478\n",
       "pop_pct_hisp         0.062863\n",
       "lfpr                 0.044032\n",
       "density              0.029483\n",
       "lower                0.054305\n",
       "similar              0.002937\n",
       "2003                 0.021893\n",
       "2004                 0.052089\n",
       "2005                 0.032065\n",
       "2006                 0.097031\n",
       "2007                -0.030403\n",
       "2008                -0.037354\n",
       "2009                -0.204247\n",
       "2010                -0.119566\n",
       "2011                 0.005404\n",
       "2012                 0.055287\n",
       "2013                 0.018699\n",
       "2014                 0.057530\n",
       "2015                 0.070377\n",
       "2016                 0.035330\n",
       "2017                 0.005861\n",
       "2018                 0.045474\n",
       "Name: pos_net_jobs, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepped.corr().iloc[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to select those that have at least a 10% correlation with our label. \n",
    "Specifically, we want the absolute value of the correlation to be weakly greater than 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pos_net_jobs', 'estabs_entry_rate', 'estabs_exit_rate', 2009, 2010], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_net_jobs_cor = np.abs(df_prepped.corr().iloc[:, 1])\n",
    "vrbls = pos_net_jobs_cor[pos_net_jobs_cor >= 0.1].index\n",
    "vrbls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neat.\n",
    "\n",
    "Now we can select the variables that we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped2 = df_prepped.loc[:, vrbls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_prepped.drop(columns = 'pos_net_jobs')\n",
    "x_train, x_test = train_test_split(x, \n",
    "                                  train_size = 2/3, \n",
    "                                  random_state = 490)\n",
    "ss = StandardScaler()\n",
    "x_train_std = pd.DataFrame(ss.fit(x_train).transform(x_train),\n",
    "                          columns = x_train.columns,\n",
    "                          index = x_train.index)\n",
    "x_test_std = pd.DataFrame(ss.fit(x_test).transform(x_test),\n",
    "                          columns = x_test.columns,\n",
    "                          index = x_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross-validate the optimal value of `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.008858667904100823}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.linspace(-5, 2, num = 20)\n",
    "}\n",
    "svc_cv = LinearSVC(dual = False)\n",
    "grid_search = GridSearchCV(svc_cv, param_grid,\n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best_10 = grid_search.best_params_\n",
    "best_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.008858667904100823, 'dual': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.linspace(-5, 2, num = 20),\n",
    "    'dual': [False]\n",
    "}\n",
    "svc_cv = LinearSVC()\n",
    "grid_search = GridSearchCV(svc_cv, param_grid,\n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best_10 = grid_search.best_params_\n",
    "best_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to refit and find the accuracy with the model with the full testing data using the optimal value of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808306900472799"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_10 = LinearSVC(C = best_10['C'], \n",
    "                         dual = False).fit(x_train_std, y_train)\n",
    "acc_10 = svc_10.score(x_test_std, y_test)\n",
    "acc_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# 5% Correlation\n",
    "[TOP](#Support-Vector-Machines---Part-1)\n",
    "\n",
    "Let's do the same thing with a weakly greater than 5% threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_net_jobs_cor = np.abs(df_prepped.corr().iloc[:, 1])\n",
    "vrbls = pos_net_jobs_cor[pos_net_jobs_cor >= 0.05].index\n",
    "df_prepped2 = df_prepped.loc[:, vrbls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_prepped.drop(columns = 'pos_net_jobs')\n",
    "x_train, x_test = train_test_split(x, \n",
    "                                  train_size = 2/3, \n",
    "                                  random_state = 490)\n",
    "ss = StandardScaler()\n",
    "x_train_std = pd.DataFrame(ss.fit(x_train).transform(x_train),\n",
    "                          columns = x_train.columns,\n",
    "                          index = x_train.index)\n",
    "x_test_std = pd.DataFrame(ss.fit(x_test).transform(x_test),\n",
    "                          columns = x_test.columns,\n",
    "                          index = x_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross-validate the optimal value of `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.008858667904100823}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.linspace(-5, 2, num = 20)\n",
    "}\n",
    "svc_cv = LinearSVC(dual = False)\n",
    "grid_search = GridSearchCV(svc_cv, param_grid,\n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best_5 = grid_search.best_params_\n",
    "best_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to refit and find the accuracy with the model with the full testing data using the optimal value of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808306900472799"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_5 = LinearSVC(C = best_5['C'], \n",
    "                         dual = False).fit(x_train_std, y_train)\n",
    "acc_5 = svc_5.score(x_test_std, y_test)\n",
    "acc_5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*copy and paste more...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****\n",
    "# 1% Correlation\n",
    "[TOP](#Support-Vector-Machines---Part-1)\n",
    "\n",
    "Let's do the same thing with a weakly greater than 5% threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_net_jobs_cor = np.abs(df_prepped.corr().iloc[:, 1])\n",
    "vrbls = pos_net_jobs_cor[pos_net_jobs_cor >= 0.01].index\n",
    "df_prepped2 = df_prepped.loc[:, vrbls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_prepped.drop(columns = 'pos_net_jobs')\n",
    "x_train, x_test = train_test_split(x, \n",
    "                                  train_size = 2/3, \n",
    "                                  random_state = 490)\n",
    "ss = StandardScaler()\n",
    "x_train_std = pd.DataFrame(ss.fit(x_train).transform(x_train),\n",
    "                          columns = x_train.columns,\n",
    "                          index = x_train.index)\n",
    "x_test_std = pd.DataFrame(ss.fit(x_test).transform(x_test),\n",
    "                          columns = x_test.columns,\n",
    "                          index = x_test.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's cross-validate the optimal value of `C`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 0.008858667904100823}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "param_grid = {\n",
    "    'C': 10.0**np.linspace(-5, 2, num = 20)\n",
    "}\n",
    "svc_cv = LinearSVC(dual = False)\n",
    "grid_search = GridSearchCV(svc_cv, param_grid,\n",
    "                          cv = 5, \n",
    "                          scoring = 'accuracy')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best_1 = grid_search.best_params_\n",
    "best_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to refit and find the accuracy with the model with the full testing data using the optimal value of `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6808306900472799"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_1 = LinearSVC(C = best_1['C'], \n",
    "                         dual = False).fit(x_train_std, y_train)\n",
    "acc_1 = svc_1.score(x_test_std, y_test)\n",
    "acc_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*copy and paste more...*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************\n",
    "# Comparison \n",
    "[TOP](#Support-Vector-Machines---Part-1)\n",
    "\n",
    "Print the percent improvement in the accuracy for each of three models. \n",
    "Which model was the best performer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% correlation accuracy gain: 21.06%\n",
      "5% correlation accuracy gain: 21.06%\n",
      "1% correlation accuracy gain: 21.06%\n"
     ]
    }
   ],
   "source": [
    "pct_10 = 100*(acc_10 - acc_null)/acc_null\n",
    "pct_5 = 100*(acc_5 - acc_null)/acc_null\n",
    "pct_1 = 100*(acc_1 - acc_null)/acc_null\n",
    "print('10% correlation accuracy gain: {0:.2f}%'.format(pct_10))\n",
    "print('5% correlation accuracy gain: {0:.2f}%'.format(pct_5))\n",
    "print('1% correlation accuracy gain: {0:.2f}%'.format(pct_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the optimal value of `C` for each model. \n",
    "Which model has the least amount of regularization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008858667904100823\n",
      "0.008858667904100823\n",
      "0.008858667904100823\n"
     ]
    }
   ],
   "source": [
    "print(best_10['C'])\n",
    "print(best_5['C'])\n",
    "print(best_1['C'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
