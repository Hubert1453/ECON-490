{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "#### Table of contents\n",
    "\n",
    "* [Overview](#Overview)\n",
    "* [Setup](#Setup)\n",
    "* [Lasso](#Lasso)\n",
    "\n",
    "# Overview\n",
    "\n",
    "This script covers how to implement two techniques:\n",
    "1. Regularization\n",
    "2. Cross-validation\n",
    "\n",
    "Regularization is a shrinkage estimator. \n",
    "By adding an additional constraint on the optimization problem, the coefficients will be smaller than their non-constrained counterparts.\n",
    "With an absolute constraint, it can be used to **select** features by setting coefficients to zero.\n",
    "The shrinkage strength is determined by a hyperpameter $\\lambda$, where $\\lambda = 0$ is no shrinkage.\n",
    "\n",
    "Cross-validation is a ubiquitous machine learning technique used **tune** hyperparameters.\n",
    "Where train-test splits are used to compare across model classes, cross-validation is used for comparing within model classes.\n",
    "See the lecture slides for more details.\n",
    "\n",
    "***\n",
    "# Setup\n",
    "[TOP](#Regularization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn import linear_model as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GeoName', 'pct_d_rgdp', 'urate_bin', 'pos_net_jobs', 'emp_estabs',\n",
       "       'estabs_entry_rate', 'estabs_exit_rate', 'pop', 'pop_pct_black',\n",
       "       'pop_pct_hisp', 'lfpr', 'density', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('C:/Users/hubst/Econ490_group/class_data.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepped = df.drop(columns = ['urate_bin', 'year', 'GeoName']).join([\n",
    "    pd.get_dummies(df['urate_bin'], drop_first = True),\n",
    "    pd.get_dummies(df.year, drop_first = True)    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_prepped['pct_d_rgdp']\n",
    "x = df_prepped.drop(columns = 'pct_d_rgdp')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "\n",
    "x_train_std = x_train.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "x_test_std  = x_test.apply(lambda x: (x - np.mean(x))/np.std(x), axis = 0)\n",
    "\n",
    "x_train_std = sm.add_constant(x_train_std)\n",
    "x_test_std  = sm.add_constant(x_test_std)\n",
    "x_train     = sm.add_constant(x_train)\n",
    "x_test      = sm.add_constant(x_test)\n",
    "\n",
    "###################################################\n",
    "# Be careful if you have a large data set.        #\n",
    "# We have created ~4 copies of the original data: #\n",
    "#                                                 #\n",
    "# 0. df                                           #\n",
    "# 1. df_prepped                                   #\n",
    "# 2. x, y                                         #\n",
    "# 3. x_train, x_test, y_train, y_test             #\n",
    "# 4. x_train_std, x_test_std                      #\n",
    "#                                                 #\n",
    "# you may run out of memeory                      #\n",
    "###################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Lasso\n",
    "[TOP](#Regularization)\n",
    "\n",
    "`statsmodels` fits an elastic-net constraint, which is a hybrid of Lasso and Ridge regression. \n",
    "It has the penalty:\n",
    "$$\n",
    "\\alpha \\left[ (1-L1\\_wt)||\\beta||_2 + L1\\_wt||\\beta||_1 \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.1764772 ,  0.07331063, -0.01526529,  0.08336556, -0.01482107,\n",
       "       -0.00042219, -0.0357732 ,  0.03635522,  0.06818012, -0.00205087,\n",
       "        0.04915225, -0.01196064,  0.02367039,  0.02543083,  0.01612287,\n",
       "        0.0579132 , -0.01519722, -0.02717455, -0.06363553,  0.02413141,\n",
       "       -0.00177043, -0.01661271,  0.0106122 , -0.01318967, -0.00675205,\n",
       "       -0.03770638, -0.01219879,  0.00823161])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_ridge = sm.OLS(y_train, x_train_std).fit_regularized(alpha = 10, L1_wt = 0)\n",
    "# note: there is no fit.summary()\n",
    "fit_ridge.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                0.0\n",
       "pos_net_jobs         0.0\n",
       "emp_estabs           0.0\n",
       "estabs_entry_rate    0.0\n",
       "estabs_exit_rate     0.0\n",
       "pop                  0.0\n",
       "pop_pct_black        0.0\n",
       "pop_pct_hisp         0.0\n",
       "lfpr                 0.0\n",
       "density              0.0\n",
       "lower                0.0\n",
       "similar              0.0\n",
       "2003                 0.0\n",
       "2004                 0.0\n",
       "2005                 0.0\n",
       "2006                 0.0\n",
       "2007                 0.0\n",
       "2008                 0.0\n",
       "2009                 0.0\n",
       "2010                 0.0\n",
       "2011                 0.0\n",
       "2012                 0.0\n",
       "2013                 0.0\n",
       "2014                 0.0\n",
       "2015                 0.0\n",
       "2016                 0.0\n",
       "2017                 0.0\n",
       "2018                 0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso = sm.OLS(y_train, x_train_std).fit_regularized(alpha = 10, L1_wt = 1)\n",
    "# note: there is no fit.summary()\n",
    "fit_lasso.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Cross-Validation \n",
    "[TOP](#Regularization)\n",
    "\n",
    "We are using a specific type of k-fold cross-validation: grid search.\n",
    "When performing grid search cross-validation, you always want to ensure that your selected hyperparameters are an interior point of the grid. \n",
    "Otherwise, you have no selected the optimal solution.\n",
    "\n",
    "The grid search function is from `sklearn`.\n",
    "Consequently, we need to use functions from the `linear_model` module: https://scikit-learn.org/stable/modules/linear_model.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.016237767391887217}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.016237767391887217"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'alpha': 10**np.linspace(-2, 2, num = 20)}\n",
    "]\n",
    "\n",
    "# We are manually supplying an intercept\n",
    "# and standardized (not normalized) the features\n",
    "cv_lasso = lm.Lasso(fit_intercept = False, normalize = False,\n",
    "                    random_state = 490)\n",
    "grid_search = GridSearchCV(cv_lasso, param_grid, cv = 5,\n",
    "                         scoring = 'neg_root_mean_squared_error')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "print(grid_search.best_params_)\n",
    "best = grid_search.best_params_['alpha']\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an interior point ($10^{-2} = 0.01$). \n",
    "We need to adjust our grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'alpha': 10**np.linspace(-5, -2, num = 20)}\n",
    "]\n",
    "\n",
    "cv_lasso = lm.Lasso(fit_intercept = False, normalize = False,\n",
    "                    random_state = 490)\n",
    "\n",
    "grid_search = GridSearchCV(cv_lasso, param_grid, cv = 5,\n",
    "                         scoring = 'neg_root_mean_squared_error')\n",
    "grid_search.fit(x_train_std, y_train)\n",
    "best = grid_search.best_params_['alpha']\n",
    "best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Once we have identified the best value of $\\alpha$, then the next step is to estimate the full model. \n",
    "We will use `statsmodels` for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const                1.931249\n",
       "pos_net_jobs         0.493323\n",
       "emp_estabs          -0.114711\n",
       "estabs_entry_rate    0.766665\n",
       "estabs_exit_rate    -0.384190\n",
       "pop                 -0.100041\n",
       "pop_pct_black        0.000000\n",
       "pop_pct_hisp         0.383635\n",
       "lfpr                 0.524511\n",
       "density             -0.027861\n",
       "lower                0.505713\n",
       "similar              0.175849\n",
       "2003                 0.055653\n",
       "2004                 0.058518\n",
       "2005                 0.076016\n",
       "2006                 0.436149\n",
       "2007                -0.319301\n",
       "2008                -0.349027\n",
       "2009                -0.591098\n",
       "2010                 0.236479\n",
       "2011                 0.000000\n",
       "2012                -0.280321\n",
       "2013                 0.010085\n",
       "2014                -0.264897\n",
       "2015                -0.208615\n",
       "2016                -0.527701\n",
       "2017                -0.216195\n",
       "2018                 0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_lasso_tuned = sm.OLS(y_train, x_train_std).fit_regularized(L1_wt = 1, alpha = best)\n",
    "fit_lasso_tuned.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Remember, a regularized model is biased.\n",
    "We will fit \n",
    "\n",
    "- a non-regularized standardized model excluding the features that are zero \n",
    "- a non-regularized, non-standardized model excluding the features that are zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pop_pct_black', 2011, 2018], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta = fit_lasso_tuned.params\n",
    "beta.index[beta == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_std_trim = x_train_std.loc[:, ~x_train_std.columns.isin(beta.index[beta == 0])]\n",
    "x_test_std_trim = x_test_std.loc[:, ~x_test_std.columns.isin(beta.index[beta == 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>      <td>0.040</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>pct_d_rgdp</td>           <td>AIC:</td>         <td>241644.5897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-03 18:35</td>        <td>BIC:</td>         <td>241855.0110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33418</td>        <td>Log-Likelihood:</td>   <td>-1.2080e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>24</td>           <td>F-statistic:</td>        <td>59.67</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33393</td>      <td>Prob (F-statistic):</td>  <td>1.40e-281</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>0.041</td>            <td>Scale:</td>          <td>80.830</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>1.9412</td>   <td>0.0492</td>   <td>39.4717</td> <td>0.0000</td> <td>1.8449</td>  <td>2.0376</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>0.4985</td>   <td>0.0531</td>   <td>9.3944</td>  <td>0.0000</td> <td>0.3945</td>  <td>0.6025</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>-0.1244</td>  <td>0.0525</td>   <td>-2.3694</td> <td>0.0178</td> <td>-0.2273</td> <td>-0.0215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>0.7741</td>   <td>0.0587</td>   <td>13.1872</td> <td>0.0000</td> <td>0.6590</td>  <td>0.8891</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>-0.4005</td>  <td>0.0570</td>   <td>-7.0309</td> <td>0.0000</td> <td>-0.5122</td> <td>-0.2889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>-0.1080</td>  <td>0.0551</td>   <td>-1.9618</td> <td>0.0498</td> <td>-0.2159</td> <td>-0.0001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>0.3970</td>   <td>0.0507</td>   <td>7.8255</td>  <td>0.0000</td> <td>0.2976</td>  <td>0.4964</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>0.5229</td>   <td>0.0573</td>   <td>9.1268</td>  <td>0.0000</td> <td>0.4106</td>  <td>0.6352</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>-0.0351</td>  <td>0.0524</td>   <td>-0.6688</td> <td>0.5036</td> <td>-0.1378</td> <td>0.0677</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>0.5305</td>   <td>0.0667</td>   <td>7.9595</td>  <td>0.0000</td> <td>0.3999</td>  <td>0.6611</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>0.2014</td>   <td>0.0574</td>   <td>3.5072</td>  <td>0.0005</td> <td>0.0888</td>  <td>0.3139</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2003</th>              <td>0.0584</td>   <td>0.0556</td>   <td>1.0517</td>  <td>0.2930</td> <td>-0.0505</td> <td>0.1673</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>0.0604</td>   <td>0.0556</td>   <td>1.0867</td>  <td>0.2772</td> <td>-0.0486</td> <td>0.1694</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>0.0868</td>   <td>0.0590</td>   <td>1.4719</td>  <td>0.1411</td> <td>-0.0288</td> <td>0.2024</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>0.4474</td>   <td>0.0605</td>   <td>7.3987</td>  <td>0.0000</td> <td>0.3289</td>  <td>0.5660</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>-0.3358</td>  <td>0.0557</td>   <td>-6.0277</td> <td>0.0000</td> <td>-0.4449</td> <td>-0.2266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>-0.3631</td>  <td>0.0554</td>   <td>-6.5538</td> <td>0.0000</td> <td>-0.4717</td> <td>-0.2545</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>-0.6025</td>  <td>0.0564</td>  <td>-10.6850</td> <td>0.0000</td> <td>-0.7130</td> <td>-0.4920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>0.2417</td>   <td>0.0555</td>   <td>4.3524</td>  <td>0.0000</td> <td>0.1328</td>  <td>0.3505</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>-0.2962</td>  <td>0.0553</td>   <td>-5.3534</td> <td>0.0000</td> <td>-0.4047</td> <td>-0.1878</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>0.0130</td>   <td>0.0553</td>   <td>0.2356</td>  <td>0.8137</td> <td>-0.0954</td> <td>0.1215</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>-0.2822</td>  <td>0.0556</td>   <td>-5.0786</td> <td>0.0000</td> <td>-0.3911</td> <td>-0.1733</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>-0.2264</td>  <td>0.0555</td>   <td>-4.0793</td> <td>0.0000</td> <td>-0.3352</td> <td>-0.1176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>-0.5459</td>  <td>0.0556</td>   <td>-9.8234</td> <td>0.0000</td> <td>-0.6548</td> <td>-0.4370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>-0.2337</td>  <td>0.0556</td>   <td>-4.2066</td> <td>0.0000</td> <td>-0.3426</td> <td>-0.1248</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>34262.381</td>  <td>Durbin-Watson:</td>       <td>1.988</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td>   <td>0.000</td>   <td>Jarque-Bera (JB):</td> <td>11837132.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>       <td>4.477</td>       <td>Prob(JB):</td>         <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>    <td>94.766</td>    <td>Condition No.:</td>         <td>3</td>     \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                  Results: Ordinary least squares\n",
       "====================================================================\n",
       "Model:              OLS              Adj. R-squared:     0.040      \n",
       "Dependent Variable: pct_d_rgdp       AIC:                241644.5897\n",
       "Date:               2021-03-03 18:35 BIC:                241855.0110\n",
       "No. Observations:   33418            Log-Likelihood:     -1.2080e+05\n",
       "Df Model:           24               F-statistic:        59.67      \n",
       "Df Residuals:       33393            Prob (F-statistic): 1.40e-281  \n",
       "R-squared:          0.041            Scale:              80.830     \n",
       "--------------------------------------------------------------------\n",
       "                     Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "--------------------------------------------------------------------\n",
       "const                1.9412   0.0492  39.4717 0.0000  1.8449  2.0376\n",
       "pos_net_jobs         0.4985   0.0531   9.3944 0.0000  0.3945  0.6025\n",
       "emp_estabs          -0.1244   0.0525  -2.3694 0.0178 -0.2273 -0.0215\n",
       "estabs_entry_rate    0.7741   0.0587  13.1872 0.0000  0.6590  0.8891\n",
       "estabs_exit_rate    -0.4005   0.0570  -7.0309 0.0000 -0.5122 -0.2889\n",
       "pop                 -0.1080   0.0551  -1.9618 0.0498 -0.2159 -0.0001\n",
       "pop_pct_hisp         0.3970   0.0507   7.8255 0.0000  0.2976  0.4964\n",
       "lfpr                 0.5229   0.0573   9.1268 0.0000  0.4106  0.6352\n",
       "density             -0.0351   0.0524  -0.6688 0.5036 -0.1378  0.0677\n",
       "lower                0.5305   0.0667   7.9595 0.0000  0.3999  0.6611\n",
       "similar              0.2014   0.0574   3.5072 0.0005  0.0888  0.3139\n",
       "2003                 0.0584   0.0556   1.0517 0.2930 -0.0505  0.1673\n",
       "2004                 0.0604   0.0556   1.0867 0.2772 -0.0486  0.1694\n",
       "2005                 0.0868   0.0590   1.4719 0.1411 -0.0288  0.2024\n",
       "2006                 0.4474   0.0605   7.3987 0.0000  0.3289  0.5660\n",
       "2007                -0.3358   0.0557  -6.0277 0.0000 -0.4449 -0.2266\n",
       "2008                -0.3631   0.0554  -6.5538 0.0000 -0.4717 -0.2545\n",
       "2009                -0.6025   0.0564 -10.6850 0.0000 -0.7130 -0.4920\n",
       "2010                 0.2417   0.0555   4.3524 0.0000  0.1328  0.3505\n",
       "2012                -0.2962   0.0553  -5.3534 0.0000 -0.4047 -0.1878\n",
       "2013                 0.0130   0.0553   0.2356 0.8137 -0.0954  0.1215\n",
       "2014                -0.2822   0.0556  -5.0786 0.0000 -0.3911 -0.1733\n",
       "2015                -0.2264   0.0555  -4.0793 0.0000 -0.3352 -0.1176\n",
       "2016                -0.5459   0.0556  -9.8234 0.0000 -0.6548 -0.4370\n",
       "2017                -0.2337   0.0556  -4.2066 0.0000 -0.3426 -0.1248\n",
       "--------------------------------------------------------------------\n",
       "Omnibus:            34262.381     Durbin-Watson:        1.988       \n",
       "Prob(Omnibus):      0.000         Jarque-Bera (JB):     11837132.892\n",
       "Skew:               4.477         Prob(JB):             0.000       \n",
       "Kurtosis:           94.766        Condition No.:        3           \n",
       "====================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_std_final = sm.OLS(y_train, x_train_std_trim).fit()\n",
    "fit_std_final.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_trim = x_train.loc[:, ~x_train.columns.isin(beta.index[beta == 0])]\n",
    "x_test_trim = x_test.loc[:, ~x_test.columns.isin(beta.index[beta == 0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>      <td>0.040</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>    <td>pct_d_rgdp</td>           <td>AIC:</td>         <td>241644.5897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2021-03-03 18:35</td>        <td>BIC:</td>         <td>241855.0110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>        <td>33418</td>        <td>Log-Likelihood:</td>   <td>-1.2080e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>             <td>24</td>           <td>F-statistic:</td>        <td>59.67</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>          <td>33393</td>      <td>Prob (F-statistic):</td>  <td>1.40e-281</td> \n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>0.041</td>            <td>Scale:</td>          <td>80.830</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>           <th>Coef.</th>  <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th> <th>[0.025</th>  <th>0.975]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>-3.1782</td>  <td>0.5046</td>   <td>-6.2983</td> <td>0.0000</td> <td>-4.1673</td> <td>-2.1891</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pos_net_jobs</th>      <td>1.0046</td>   <td>0.1069</td>   <td>9.3944</td>  <td>0.0000</td> <td>0.7950</td>  <td>1.2142</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>emp_estabs</th>        <td>-0.0265</td>  <td>0.0112</td>   <td>-2.3694</td> <td>0.0178</td> <td>-0.0485</td> <td>-0.0046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_entry_rate</th> <td>0.2604</td>   <td>0.0197</td>   <td>13.1872</td> <td>0.0000</td> <td>0.2217</td>  <td>0.2990</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>estabs_exit_rate</th>  <td>-0.1583</td>  <td>0.0225</td>   <td>-7.0309</td> <td>0.0000</td> <td>-0.2025</td> <td>-0.1142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop</th>               <td>-0.0000</td>  <td>0.0000</td>   <td>-1.9618</td> <td>0.0498</td> <td>-0.0000</td> <td>-0.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>pop_pct_hisp</th>      <td>0.0305</td>   <td>0.0039</td>   <td>7.8255</td>  <td>0.0000</td> <td>0.0229</td>  <td>0.0382</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lfpr</th>              <td>0.0480</td>   <td>0.0053</td>   <td>9.1268</td>  <td>0.0000</td> <td>0.0377</td>  <td>0.0583</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>density</th>           <td>-0.0000</td>  <td>0.0000</td>   <td>-0.6688</td> <td>0.5036</td> <td>-0.0001</td> <td>0.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lower</th>             <td>1.0935</td>   <td>0.1374</td>   <td>7.9595</td>  <td>0.0000</td> <td>0.8242</td>  <td>1.3628</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>similar</th>           <td>0.5213</td>   <td>0.1486</td>   <td>3.5072</td>  <td>0.0005</td> <td>0.2300</td>  <td>0.8126</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2003</th>              <td>0.2469</td>   <td>0.2348</td>   <td>1.0517</td>  <td>0.2930</td> <td>-0.2133</td> <td>0.7071</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2004</th>              <td>0.2556</td>   <td>0.2352</td>   <td>1.0867</td>  <td>0.2772</td> <td>-0.2054</td> <td>0.7166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2005</th>              <td>0.3685</td>   <td>0.2503</td>   <td>1.4719</td>  <td>0.1411</td> <td>-0.1222</td> <td>0.8591</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2006</th>              <td>1.8775</td>   <td>0.2538</td>   <td>7.3987</td>  <td>0.0000</td> <td>1.3801</td>  <td>2.3749</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2007</th>              <td>-1.4109</td>  <td>0.2341</td>   <td>-6.0277</td> <td>0.0000</td> <td>-1.8696</td> <td>-0.9521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2008</th>              <td>-1.5361</td>  <td>0.2344</td>   <td>-6.5538</td> <td>0.0000</td> <td>-1.9955</td> <td>-1.0767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2009</th>              <td>-2.5734</td>  <td>0.2408</td>  <td>-10.6850</td> <td>0.0000</td> <td>-3.0455</td> <td>-2.1014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2010</th>              <td>1.0264</td>   <td>0.2358</td>   <td>4.3524</td>  <td>0.0000</td> <td>0.5642</td>  <td>1.4886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2012</th>              <td>-1.2668</td>  <td>0.2366</td>   <td>-5.3534</td> <td>0.0000</td> <td>-1.7306</td> <td>-0.8030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2013</th>              <td>0.0557</td>   <td>0.2363</td>   <td>0.2356</td>  <td>0.8137</td> <td>-0.4075</td> <td>0.5189</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2014</th>              <td>-1.2035</td>  <td>0.2370</td>   <td>-5.0786</td> <td>0.0000</td> <td>-1.6679</td> <td>-0.7390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2015</th>              <td>-0.9732</td>  <td>0.2386</td>   <td>-4.0793</td> <td>0.0000</td> <td>-1.4408</td> <td>-0.5056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2016</th>              <td>-2.3327</td>  <td>0.2375</td>   <td>-9.8234</td> <td>0.0000</td> <td>-2.7981</td> <td>-1.8672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2017</th>              <td>-0.9854</td>  <td>0.2342</td>   <td>-4.2066</td> <td>0.0000</td> <td>-1.4445</td> <td>-0.5262</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>34262.381</td>  <td>Durbin-Watson:</td>       <td>1.988</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td>   <td>0.000</td>   <td>Jarque-Bera (JB):</td> <td>11837132.892</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>       <td>4.477</td>       <td>Prob(JB):</td>         <td>0.000</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>    <td>94.766</td>    <td>Condition No.:</td>      <td>3812400</td>  \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                  Results: Ordinary least squares\n",
       "====================================================================\n",
       "Model:              OLS              Adj. R-squared:     0.040      \n",
       "Dependent Variable: pct_d_rgdp       AIC:                241644.5897\n",
       "Date:               2021-03-03 18:35 BIC:                241855.0110\n",
       "No. Observations:   33418            Log-Likelihood:     -1.2080e+05\n",
       "Df Model:           24               F-statistic:        59.67      \n",
       "Df Residuals:       33393            Prob (F-statistic): 1.40e-281  \n",
       "R-squared:          0.041            Scale:              80.830     \n",
       "--------------------------------------------------------------------\n",
       "                     Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
       "--------------------------------------------------------------------\n",
       "const               -3.1782   0.5046  -6.2983 0.0000 -4.1673 -2.1891\n",
       "pos_net_jobs         1.0046   0.1069   9.3944 0.0000  0.7950  1.2142\n",
       "emp_estabs          -0.0265   0.0112  -2.3694 0.0178 -0.0485 -0.0046\n",
       "estabs_entry_rate    0.2604   0.0197  13.1872 0.0000  0.2217  0.2990\n",
       "estabs_exit_rate    -0.1583   0.0225  -7.0309 0.0000 -0.2025 -0.1142\n",
       "pop                 -0.0000   0.0000  -1.9618 0.0498 -0.0000 -0.0000\n",
       "pop_pct_hisp         0.0305   0.0039   7.8255 0.0000  0.0229  0.0382\n",
       "lfpr                 0.0480   0.0053   9.1268 0.0000  0.0377  0.0583\n",
       "density             -0.0000   0.0000  -0.6688 0.5036 -0.0001  0.0000\n",
       "lower                1.0935   0.1374   7.9595 0.0000  0.8242  1.3628\n",
       "similar              0.5213   0.1486   3.5072 0.0005  0.2300  0.8126\n",
       "2003                 0.2469   0.2348   1.0517 0.2930 -0.2133  0.7071\n",
       "2004                 0.2556   0.2352   1.0867 0.2772 -0.2054  0.7166\n",
       "2005                 0.3685   0.2503   1.4719 0.1411 -0.1222  0.8591\n",
       "2006                 1.8775   0.2538   7.3987 0.0000  1.3801  2.3749\n",
       "2007                -1.4109   0.2341  -6.0277 0.0000 -1.8696 -0.9521\n",
       "2008                -1.5361   0.2344  -6.5538 0.0000 -1.9955 -1.0767\n",
       "2009                -2.5734   0.2408 -10.6850 0.0000 -3.0455 -2.1014\n",
       "2010                 1.0264   0.2358   4.3524 0.0000  0.5642  1.4886\n",
       "2012                -1.2668   0.2366  -5.3534 0.0000 -1.7306 -0.8030\n",
       "2013                 0.0557   0.2363   0.2356 0.8137 -0.4075  0.5189\n",
       "2014                -1.2035   0.2370  -5.0786 0.0000 -1.6679 -0.7390\n",
       "2015                -0.9732   0.2386  -4.0793 0.0000 -1.4408 -0.5056\n",
       "2016                -2.3327   0.2375  -9.8234 0.0000 -2.7981 -1.8672\n",
       "2017                -0.9854   0.2342  -4.2066 0.0000 -1.4445 -0.5262\n",
       "--------------------------------------------------------------------\n",
       "Omnibus:            34262.381     Durbin-Watson:        1.988       \n",
       "Prob(Omnibus):      0.000         Jarque-Bera (JB):     11837132.892\n",
       "Skew:               4.477         Prob(JB):             0.000       \n",
       "Kurtosis:           94.766        Condition No.:        3812400     \n",
       "====================================================================\n",
       "* The condition number is large (4e+06). This might indicate\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_final = sm.OLS(y_train, x_train_trim).fit()\n",
    "fit_final.summary2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Lastly, we will test the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.295172646932564"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_null = np.sqrt(np.mean(  (y_test - np.mean(y_train))**2  ))\n",
    "rmse_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.103321461021201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_lasso = np.sqrt(np.mean(  (y_test - fit_lasso_tuned.predict(x_test_std))**2  ))\n",
    "print(rmse_lasso)\n",
    "round((rmse_lasso - rmse_null)/rmse_null*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.103231259163913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.06"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_std_final = np.sqrt(np.mean(  (y_test - fit_std_final.predict(x_test_std_trim))**2  ))\n",
    "print(rmse_std_final)\n",
    "round((rmse_std_final - rmse_null)/rmse_null*100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.103358969607513\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_final = np.sqrt(np.mean(  (y_test - fit_final.predict(x_test_trim))**2  ))\n",
    "print(rmse_final)\n",
    "round((rmse_final - rmse_null)/rmse_null*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward selection gave us a 1.37% reduction in RMSE. \n",
    "\n",
    "# What does ^ tell you about statistical significance for predictive power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
