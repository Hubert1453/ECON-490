{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Python\n",
    "\n",
    "#### Table of Contents\n",
    "* [Setup](#Setup)\n",
    "* [statsmodels.api](#statsmodels.api)\n",
    "    - [sm Training](#sm-Training)\n",
    "    - [sm Predicting](#sm-Predicting)\n",
    "    - [sm Training](#sm-Training)\n",
    "* [statsmodels.formula.api](#statsmodels.formula.api)\n",
    "    - [smf Training](#smf-Training)\n",
    "    - [smf Predicting](#smf-Predicting)\n",
    "    - [smf Training](#smf-Training)\n",
    "    - [smf Formulas](#smf-Formulas)\n",
    "* [sklearn.linear_model](#sklearn.linear_model)\n",
    "    - [sklearn Training](#sklearn-Training)\n",
    "    - [sklearn Predicting](#sklearn-Predicting)\n",
    "    - [sklearn Training](#sklearn-Training)\n",
    "\n",
    "We are going to estimate a linear regression model using three different functions. \n",
    "The different packages demonstrate the bigger picture of what each field cares about.\n",
    "`statsmodels` is focused towards statistics and econometrics, so it has much more formal output.\n",
    "We will demonstrate the base API and the R-like formula API.\n",
    "`sklearn` is focused towards machine learning, which is focused only on $\\hat{y}$.\n",
    "\n",
    "We are going to use the following regression:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    \\%\\Delta rGDP_{i,t} = & \\alpha_t + UrateBin_{i,t}^\\prime\\beta + LFPR_{i,t}\\gamma + LFPR_{i,t}UrateBin_{i,t}\\delta +\\\\\n",
    "    & EmpPerEstab_{i,t}\\zeta + EmpPerEstab_{i,t}^2\\eta + \\epsilon_{i,t}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "*********\n",
    "# Setup\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GeoName', 'pct_d_rgdp', 'urate_bin', 'pos_net_jobs', 'emp_estabs',\n",
       "       'estabs_entry_rate', 'estabs_exit_rate', 'pop', 'pop_pct_black',\n",
       "       'pop_pct_hisp', 'lfpr', 'density', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('C:/Users/hubst/Econ490_group/class_data.pkl')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but `statsmodels.formula` require the features and labels to be separate arguments. So, let's create them!\n",
    "\n",
    "**IMPORTANT** The features matrix is the **design matrix**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['const', 'emp_estabs', 'emp_estabs_sq', 'lfpr', 'lfpr:urate_lower',\n",
       "       'lfpr:urate_similar', 'urate_lower', 'urate_similar', 'year_2003',\n",
       "       'year_2004', 'year_2005', 'year_2006', 'year_2007', 'year_2008',\n",
       "       'year_2009', 'year_2010', 'year_2011', 'year_2012', 'year_2013',\n",
       "       'year_2014', 'year_2015', 'year_2016', 'year_2017', 'year_2018'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['pct_d_rgdp']\n",
    "x = df.drop(columns = 'pct_d_rgdp')\n",
    "\n",
    "# Creating dummies\n",
    "x = x.join([pd.get_dummies(x['year'], prefix = 'year', drop_first = True),\n",
    "          pd.get_dummies(x['urate_bin'], prefix = 'urate', drop_first = True)]).drop(columns = ['year', 'urate_bin'])\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "# Creating interactions\n",
    "x['lfpr:urate_lower'] = x.lfpr * x.urate_lower\n",
    "x['lfpr:urate_similar'] = x.lfpr * x.urate_similar\n",
    "x['emp_estabs_sq'] = x.emp_estabs**2\n",
    "\n",
    "# Dropping features we do not want to use\n",
    "x.drop(columns = ['GeoName', 'pos_net_jobs', 'estabs_entry_rate', 'estabs_exit_rate',\n",
    "                  'pop', 'pop_pct_black', 'pop_pct_hisp', 'density'], inplace = True)\n",
    "\n",
    "# Sorting the columns for output\n",
    "x.sort_index(axis = 'columns', inplace = True)\n",
    "\n",
    "# Dropping un\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33418, 24)\n",
      "(33418,) \n",
      "\n",
      "(16709, 24)\n",
      "(16709,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 2/3, random_state = 490)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape, '\\n')\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "# statsmodels.api\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`statsmodels.api`'s linear regresion is a capitalized OLS.\n",
    "\n",
    "This package is also one of the few that use the order (y, x) instead of (x, y). Be careful out there! Read the documentation when available!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sm Training \n",
    "[TOP](#OLS-Python)\n",
    "\n",
    "Fitting `statsmodels` functions proceeds as follows\n",
    "\n",
    "1. calling the desired function with `y` and `x` arguments.\n",
    "2. chain the `.fit()` method\n",
    "\n",
    "This is different than `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             pct_d_rgdp   R-squared:                       0.030\n",
      "Model:                            OLS   Adj. R-squared:                  0.029\n",
      "Method:                 Least Squares   F-statistic:                     44.42\n",
      "Date:                Tue, 23 Feb 2021   Prob (F-statistic):          5.23e-198\n",
      "Time:                        14:15:31   Log-Likelihood:            -1.2100e+05\n",
      "No. Observations:               33418   AIC:                         2.420e+05\n",
      "Df Residuals:                   33394   BIC:                         2.422e+05\n",
      "Df Model:                          23                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "const                 -0.5453      0.637     -0.856      0.392      -1.794       0.703\n",
      "emp_estabs            -0.0495      0.025     -1.976      0.048      -0.099      -0.000\n",
      "emp_estabs_sq          0.0007      0.001      1.076      0.282      -0.001       0.002\n",
      "lfpr                   0.0431      0.008      5.443      0.000       0.028       0.059\n",
      "lfpr:urate_lower       0.0072      0.011      0.637      0.524      -0.015       0.030\n",
      "lfpr:urate_similar    -0.0258      0.016     -1.590      0.112      -0.058       0.006\n",
      "urate_lower            0.8578      0.879      0.975      0.329      -0.866       2.581\n",
      "urate_similar          2.6067      1.205      2.164      0.030       0.246       4.968\n",
      "year_2003             -0.0279      0.288     -0.097      0.923      -0.592       0.536\n",
      "year_2004              0.0965      0.288      0.335      0.737      -0.468       0.661\n",
      "year_2005              0.4150      0.302      1.373      0.170      -0.178       1.008\n",
      "year_2006              2.2763      0.301      7.559      0.000       1.686       2.867\n",
      "year_2007             -1.7150      0.287     -5.980      0.000      -2.277      -1.153\n",
      "year_2008             -2.3041      0.288     -8.006      0.000      -2.868      -1.740\n",
      "year_2009             -3.9988      0.290    -13.807      0.000      -4.566      -3.431\n",
      "year_2010              0.0382      0.289      0.132      0.895      -0.528       0.604\n",
      "year_2011             -1.0769      0.289     -3.730      0.000      -1.643      -0.511\n",
      "year_2012             -1.7195      0.290     -5.935      0.000      -2.287      -1.152\n",
      "year_2013             -0.5101      0.290     -1.762      0.078      -1.078       0.057\n",
      "year_2014             -1.5890      0.289     -5.493      0.000      -2.156      -1.022\n",
      "year_2015             -1.3265      0.291     -4.565      0.000      -1.896      -0.757\n",
      "year_2016             -2.7106      0.290     -9.360      0.000      -3.278      -2.143\n",
      "year_2017             -1.6160      0.288     -5.620      0.000      -2.180      -1.052\n",
      "year_2018             -0.7263      0.291     -2.494      0.013      -1.297      -0.155\n",
      "==============================================================================\n",
      "Omnibus:                    34489.237   Durbin-Watson:                   1.987\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         12028851.420\n",
      "Skew:                           4.530   Prob(JB):                         0.00\n",
      "Kurtosis:                      95.503   Cond. No.                     7.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 7.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "fit_sm = sm.OLS(y_train, x_train).fit()\n",
    "print(fit_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Results: Ordinary least squares\n",
      "====================================================================\n",
      "Model:              OLS              Adj. R-squared:     0.029      \n",
      "Dependent Variable: pct_d_rgdp       AIC:                242038.7314\n",
      "Date:               2021-02-23 14:15 BIC:                242240.7358\n",
      "No. Observations:   33418            Log-Likelihood:     -1.2100e+05\n",
      "Df Model:           23               F-statistic:        44.42      \n",
      "Df Residuals:       33394            Prob (F-statistic): 5.23e-198  \n",
      "R-squared:          0.030            Scale:              81.791     \n",
      "--------------------------------------------------------------------\n",
      "                     Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
      "--------------------------------------------------------------------\n",
      "const               -0.5453   0.6370  -0.8562 0.3919 -1.7938  0.7031\n",
      "emp_estabs          -0.0495   0.0251  -1.9763 0.0481 -0.0987 -0.0004\n",
      "emp_estabs_sq        0.0007   0.0007   1.0757 0.2821 -0.0006  0.0020\n",
      "lfpr                 0.0431   0.0079   5.4432 0.0000  0.0276  0.0586\n",
      "lfpr:urate_lower     0.0072   0.0114   0.6367 0.5243 -0.0151  0.0296\n",
      "lfpr:urate_similar  -0.0258   0.0162  -1.5905 0.1117 -0.0576  0.0060\n",
      "urate_lower          0.8578   0.8794   0.9755 0.3293 -0.8658  2.5815\n",
      "urate_similar        2.6067   1.2046   2.1640 0.0305  0.2456  4.9678\n",
      "year_2003           -0.0279   0.2876  -0.0971 0.9227 -0.5916  0.5358\n",
      "year_2004            0.0965   0.2878   0.3352 0.7375 -0.4676  0.6606\n",
      "year_2005            0.4150   0.3023   1.3729 0.1698 -0.1775  1.0075\n",
      "year_2006            2.2763   0.3011   7.5587 0.0000  1.6860  2.8665\n",
      "year_2007           -1.7150   0.2868  -5.9800 0.0000 -2.2771 -1.1529\n",
      "year_2008           -2.3041   0.2878  -8.0056 0.0000 -2.8683 -1.7400\n",
      "year_2009           -3.9988   0.2896 -13.8071 0.0000 -4.5664 -3.4311\n",
      "year_2010            0.0382   0.2888   0.1323 0.8948 -0.5279  0.6043\n",
      "year_2011           -1.0769   0.2887  -3.7300 0.0002 -1.6427 -0.5110\n",
      "year_2012           -1.7195   0.2897  -5.9351 0.0000 -2.2873 -1.1516\n",
      "year_2013           -0.5101   0.2896  -1.7617 0.0781 -1.0777  0.0574\n",
      "year_2014           -1.5890   0.2893  -5.4931 0.0000 -2.1560 -1.0220\n",
      "year_2015           -1.3265   0.2906  -4.5652 0.0000 -1.8960 -0.7570\n",
      "year_2016           -2.7106   0.2896  -9.3602 0.0000 -3.2783 -2.1430\n",
      "year_2017           -1.6160   0.2875  -5.6200 0.0000 -2.1796 -1.0524\n",
      "year_2018           -0.7263   0.2913  -2.4936 0.0127 -1.2972 -0.1554\n",
      "--------------------------------------------------------------------\n",
      "Omnibus:            34489.237     Durbin-Watson:        1.987       \n",
      "Prob(Omnibus):      0.000         Jarque-Bera (JB):     12028851.420\n",
      "Skew:               4.530         Prob(JB):             0.000       \n",
      "Kurtosis:           95.503        Condition No.:        7266        \n",
      "====================================================================\n",
      "* The condition number is large (7e+03). This might indicate\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "print(fit_sm.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029684707680828093"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_sm.params\n",
    "fit_sm.pvalues\n",
    "fit_sm.resid\n",
    "fit_sm.conf_int(alpha = 0.01)\n",
    "fit_sm.rsquared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sm Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fips   year\n",
       "17195  2003    2.228947\n",
       "30025  2006    5.982549\n",
       "48279  2008    1.897888\n",
       "37011  2002    1.666423\n",
       "19111  2014    1.271692\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_sm = fit_sm.predict(x_test)\n",
    "y_hat_sm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sm Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.174408715923855"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sm = np.sqrt(np.mean((y_test - y_hat_sm)**2))\n",
    "rmse_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is this fit, you ask. \n",
    "Well, it is a bit a little difficult to say without comparison.\n",
    "A good starting place is to compare this fit against the null model.\n",
    "Then we can determine the percent improvement we obtain from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.295172646932564"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# null model\n",
    "rmse_null = np.sqrt(  np.mean((y_test - np.mean(y_train))**2)  )\n",
    "rmse_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3%\n"
     ]
    }
   ],
   "source": [
    "print(round((rmse_null - rmse_sm)/rmse_null*100, 2), '%', sep = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 1.25%!? \n",
    "That is not much at all!\n",
    "\n",
    "We should note that if we have made a 100% imporvement, then we have interpolated the data (overfit it).\n",
    "I would say if we could improve upon the null model by 10%, then that is something to be excited about.\n",
    "Let's see if we can get there this semester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# statsmodels.formula.api\n",
    "[TOP](#OLS-Python)\n",
    "\n",
    "This works just like `R`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GeoName', 'pct_d_rgdp', 'urate_bin', 'pos_net_jobs', 'emp_estabs',\n",
       "       'estabs_entry_rate', 'estabs_exit_rate', 'pop', 'pop_pct_black',\n",
       "       'pop_pct_hisp', 'lfpr', 'density', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here is something cool about `train_test_split()` with a specified `random_state`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, train_size = 2/3, random_state = 490)\n",
    "all(x_train.index == df_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smf Training\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Results: Ordinary least squares\n",
      "=============================================================================\n",
      "Model:                 OLS                 Adj. R-squared:        0.029      \n",
      "Dependent Variable:    pct_d_rgdp          AIC:                   242038.7314\n",
      "Date:                  2021-02-23 14:15    BIC:                   242240.7358\n",
      "No. Observations:      33418               Log-Likelihood:        -1.2100e+05\n",
      "Df Model:              23                  F-statistic:           44.42      \n",
      "Df Residuals:          33394               Prob (F-statistic):    5.23e-198  \n",
      "R-squared:             0.030               Scale:                 81.791     \n",
      "-----------------------------------------------------------------------------\n",
      "                              Coef.  Std.Err.    t     P>|t|   [0.025  0.975]\n",
      "-----------------------------------------------------------------------------\n",
      "Intercept                    -0.5453   0.6370  -0.8562 0.3919 -1.7938  0.7031\n",
      "C(urate_bin)[T.lower]         0.8578   0.8794   0.9755 0.3293 -0.8658  2.5815\n",
      "C(urate_bin)[T.similar]       2.6067   1.2046   2.1640 0.0305  0.2456  4.9678\n",
      "C(year)[T.2003]              -0.0279   0.2876  -0.0971 0.9227 -0.5916  0.5358\n",
      "C(year)[T.2004]               0.0965   0.2878   0.3352 0.7375 -0.4676  0.6606\n",
      "C(year)[T.2005]               0.4150   0.3023   1.3729 0.1698 -0.1775  1.0075\n",
      "C(year)[T.2006]               2.2763   0.3011   7.5587 0.0000  1.6860  2.8665\n",
      "C(year)[T.2007]              -1.7150   0.2868  -5.9800 0.0000 -2.2771 -1.1529\n",
      "C(year)[T.2008]              -2.3041   0.2878  -8.0056 0.0000 -2.8683 -1.7400\n",
      "C(year)[T.2009]              -3.9988   0.2896 -13.8071 0.0000 -4.5664 -3.4311\n",
      "C(year)[T.2010]               0.0382   0.2888   0.1323 0.8948 -0.5279  0.6043\n",
      "C(year)[T.2011]              -1.0769   0.2887  -3.7300 0.0002 -1.6427 -0.5110\n",
      "C(year)[T.2012]              -1.7195   0.2897  -5.9351 0.0000 -2.2873 -1.1516\n",
      "C(year)[T.2013]              -0.5101   0.2896  -1.7617 0.0781 -1.0777  0.0574\n",
      "C(year)[T.2014]              -1.5890   0.2893  -5.4931 0.0000 -2.1560 -1.0220\n",
      "C(year)[T.2015]              -1.3265   0.2906  -4.5652 0.0000 -1.8960 -0.7570\n",
      "C(year)[T.2016]              -2.7106   0.2896  -9.3602 0.0000 -3.2783 -2.1430\n",
      "C(year)[T.2017]              -1.6160   0.2875  -5.6200 0.0000 -2.1796 -1.0524\n",
      "C(year)[T.2018]              -0.7263   0.2913  -2.4936 0.0127 -1.2972 -0.1554\n",
      "emp_estabs                   -0.0495   0.0251  -1.9763 0.0481 -0.0987 -0.0004\n",
      "I(emp_estabs ** 2)            0.0007   0.0007   1.0757 0.2821 -0.0006  0.0020\n",
      "lfpr                          0.0431   0.0079   5.4432 0.0000  0.0276  0.0586\n",
      "C(urate_bin)[T.lower]:lfpr    0.0072   0.0114   0.6367 0.5243 -0.0151  0.0296\n",
      "C(urate_bin)[T.similar]:lfpr -0.0258   0.0162  -1.5905 0.1117 -0.0576  0.0060\n",
      "-----------------------------------------------------------------------------\n",
      "Omnibus:               34489.237        Durbin-Watson:           1.987       \n",
      "Prob(Omnibus):         0.000            Jarque-Bera (JB):        12028851.420\n",
      "Skew:                  4.530            Prob(JB):                0.000       \n",
      "Kurtosis:              95.503           Condition No.:           7266        \n",
      "=============================================================================\n",
      "* The condition number is large (7e+03). This might indicate\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "fit_smf = smf.ols(formula = 'pct_d_rgdp ~ emp_estabs + I(emp_estabs**2) + C(urate_bin)*lfpr + C(year)', data = df_train).fit()\n",
    "print(fit_smf.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smf Predicting\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_smf = fit_smf.predict(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smf Testing\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.174408715923862"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_smf = np.sqrt(  np.mean((yhat_smf - y_test)**2)  )\n",
    "rmse_smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.174408715923855"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## smf Formulas\n",
    "[TOP](#OLS-Python)\n",
    "\n",
    "Here are a few more examples on how to use formulas in `statsmodels.formula.api`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GeoName', 'pct_d_rgdp', 'urate_bin', 'pos_net_jobs', 'emp_estabs',\n",
       "       'estabs_entry_rate', 'estabs_exit_rate', 'pop', 'pop_pct_black',\n",
       "       'pop_pct_hisp', 'lfpr', 'density', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "density    0.000024\n",
       "pop        0.000002\n",
       "dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no intercept\n",
    "smf.ols(formula = 'pct_d_rgdp ~ density + pop - 1', data = df_train).fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept                                    1.872175\n",
       "I(year == 2003)[T.True]                      1.159957\n",
       "I(year.isin([range(2007, 2010)]))[T.True]    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only specific levels\n",
    "smf.ols(formula = \"pct_d_rgdp ~ I(year == 2003) + I(year.isin([range(2007,2010)]))\", data = df_train).fit().params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*********\n",
    "# sklearn.linear_model\n",
    "[TOP](#OLS-Python)\n",
    "\n",
    "`sklearn`, the best machine learning package for everything *other than* neural networks. \n",
    "The lack of statistical details from their OLS function goes to show what is the difference between data scientists and statisticians/econometricians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Training \n",
    "[TOP](#OLS-Python)\n",
    "\n",
    "Fitting `sklearn` functions proceeds as follows:\n",
    "\n",
    "1. call the desired function without arguments\n",
    "2. chain the `.fit()` method with `x` and `y` arguments\n",
    "\n",
    "This is different than `statsmodels`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029684707680828093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -4.95321015e-02,  7.02136460e-04,  4.31047751e-02,\n",
       "        7.24794039e-03, -2.57808743e-02,  8.57828839e-01,  2.60672027e+00,\n",
       "       -2.79203830e-02,  9.64688694e-02,  4.15018524e-01,  2.27628941e+00,\n",
       "       -1.71496729e+00, -2.30414244e+00, -3.99878144e+00,  3.82062093e-02,\n",
       "       -1.07687250e+00, -1.71948367e+00, -5.10131372e-01, -1.58904658e+00,\n",
       "       -1.32647063e+00, -2.71064185e+00, -1.61600204e+00, -7.26279146e-01])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_sk = LinearRegression().fit(x_train, y_train)\n",
    "print(fit_sk.score(x_train, y_train)) # r_sq\n",
    "fit_sk.coef_ # unamed coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Predicting\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_sk = fit_sk.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn Testing\n",
    "[TOP](#OLS-Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.174408715923867"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sk = mean_squared_error(yhat_sk, y_test, squared = False)\n",
    "rmse_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.174408715923855"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.174408715923862"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_smf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
